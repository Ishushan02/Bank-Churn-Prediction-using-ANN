{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('bank_Churn_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1, inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing for if  there is any unique dataset in Object dtatype to convert in to Numeric Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France' 'Spain' 'Germany']\n",
      "['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "for column in data:\n",
    "    if data[column].dtypes == 'object':\n",
    "        print(data[column].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing the categorical data to its numeric form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Gender'].replace({'Female':1, 'Male':0}, inplace = True)\n",
    "data['Geography'].replace({'France':0, 'Spain':1, 'Germany':2}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          0       1   42       2       0.00              1   \n",
       "1          608          1       1   41       1   83807.86              1   \n",
       "2          502          0       1   42       8  159660.80              3   \n",
       "3          699          0       1   39       1       0.00              2   \n",
       "4          850          1       1   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data:\n",
    "    if data[column].dtypes == 'object':\n",
    "        print(data[column].unique())\n",
    "#there are no unique elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the data for the columns ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          0       1   42       2       0.00              1   \n",
       "1          608          1       1   41       1   83807.86              1   \n",
       "2          502          0       1   42       8  159660.80              3   \n",
       "3          699          0       1   39       1       0.00              2   \n",
       "4          850          1       1   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaling_column = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "data[scaling_column] = scaler.fit_transform(data[scaling_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.516</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283784</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.500246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender       Age  Tenure   Balance  NumOfProducts  \\\n",
       "0        0.538          0       1  0.324324     0.2  0.000000              1   \n",
       "1        0.516          1       1  0.310811     0.1  0.334031              1   \n",
       "2        0.304          0       1  0.324324     0.8  0.636357              3   \n",
       "3        0.698          0       1  0.283784     0.1  0.000000              2   \n",
       "4        1.000          1       1  0.337838     0.2  0.500246              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1         0.506735       1  \n",
       "1          0               1         0.562709       0  \n",
       "2          1               0         0.569654       1  \n",
       "3          0               0         0.469120       0  \n",
       "4          1               1         0.395400       0  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocating the X dataset and y dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Exited', axis = 1)\n",
    "y = data['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset with 80% training model and 20 % testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 10), (2000, 10))"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Artificial Neural Network Model using mini btch gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I have taken mini batch size as 10 because to get high accuracy evenhough it takes time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 0.4896 - acc: 0.7950\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 2s 211us/sample - loss: 0.4509 - acc: 0.8067\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 2s 208us/sample - loss: 0.4288 - acc: 0.8146\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 2s 213us/sample - loss: 0.4101 - acc: 0.8219\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 2s 210us/sample - loss: 0.3958 - acc: 0.8325\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 2s 232us/sample - loss: 0.3850 - acc: 0.8354\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 2s 243us/sample - loss: 0.3768 - acc: 0.8421\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 2s 214us/sample - loss: 0.3690 - acc: 0.8446\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 2s 220us/sample - loss: 0.3621 - acc: 0.8485\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 2s 206us/sample - loss: 0.3587 - acc: 0.8495\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 2s 205us/sample - loss: 0.3556 - acc: 0.8521\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 2s 203us/sample - loss: 0.3548 - acc: 0.8528\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 2s 222us/sample - loss: 0.3524 - acc: 0.8530\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 2s 207us/sample - loss: 0.3506 - acc: 0.8554\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 2s 214us/sample - loss: 0.3504 - acc: 0.8549\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 2s 260us/sample - loss: 0.3502 - acc: 0.8539\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 2s 216us/sample - loss: 0.3488 - acc: 0.8546\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 2s 224us/sample - loss: 0.3467 - acc: 0.8586\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 2s 208us/sample - loss: 0.3471 - acc: 0.8584\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 2s 214us/sample - loss: 0.3466 - acc: 0.8568\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 2s 211us/sample - loss: 0.3464 - acc: 0.8574\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 2s 209us/sample - loss: 0.3450 - acc: 0.8585\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 2s 210us/sample - loss: 0.3449 - acc: 0.8566\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 2s 217us/sample - loss: 0.3441 - acc: 0.8595\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 2s 301us/sample - loss: 0.3447 - acc: 0.8605\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 2s 271us/sample - loss: 0.3435 - acc: 0.8579\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 2s 271us/sample - loss: 0.3438 - acc: 0.8565\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 2s 254us/sample - loss: 0.3437 - acc: 0.8564\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 2s 255us/sample - loss: 0.3427 - acc: 0.8581\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 2s 255us/sample - loss: 0.3424 - acc: 0.8597\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 2s 252us/sample - loss: 0.3418 - acc: 0.8587\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 2s 269us/sample - loss: 0.3419 - acc: 0.8591\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 2s 273us/sample - loss: 0.3415 - acc: 0.8584\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 2s 276us/sample - loss: 0.3409 - acc: 0.8571\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 2s 252us/sample - loss: 0.3418 - acc: 0.8597\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 2s 252us/sample - loss: 0.3403 - acc: 0.8597\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 2s 251us/sample - loss: 0.3416 - acc: 0.8597\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 2s 255us/sample - loss: 0.3401 - acc: 0.8589\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 2s 256us/sample - loss: 0.3397 - acc: 0.8584\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 3s 326us/sample - loss: 0.3407 - acc: 0.8574\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 2s 297us/sample - loss: 0.3405 - acc: 0.8586\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 2s 304us/sample - loss: 0.3398 - acc: 0.8606\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 2s 283us/sample - loss: 0.3380 - acc: 0.8634\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 2s 295us/sample - loss: 0.3389 - acc: 0.8619\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 2s 284us/sample - loss: 0.3385 - acc: 0.8608\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 2s 287us/sample - loss: 0.3396 - acc: 0.8606\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 3s 353us/sample - loss: 0.3384 - acc: 0.8601\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 2s 293us/sample - loss: 0.3380 - acc: 0.8605\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 2s 302us/sample - loss: 0.3391 - acc: 0.8596\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 2s 285us/sample - loss: 0.3388 - acc: 0.8594\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 2s 298us/sample - loss: 0.3371 - acc: 0.8625\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 2s 298us/sample - loss: 0.3380 - acc: 0.8625\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 2s 304us/sample - loss: 0.3367 - acc: 0.8619\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 3s 322us/sample - loss: 0.3381 - acc: 0.8604\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 3s 313us/sample - loss: 0.3385 - acc: 0.8601\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 2s 299us/sample - loss: 0.3367 - acc: 0.8591\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 3s 319us/sample - loss: 0.3372 - acc: 0.8586\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 2s 311us/sample - loss: 0.3366 - acc: 0.8619\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 2s 286us/sample - loss: 0.3367 - acc: 0.8633\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 3s 358us/sample - loss: 0.3372 - acc: 0.8618\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 2s 293us/sample - loss: 0.3364 - acc: 0.8612\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 2s 304us/sample - loss: 0.3363 - acc: 0.8589\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 2s 283us/sample - loss: 0.3359 - acc: 0.8595\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 2s 299us/sample - loss: 0.3356 - acc: 0.8616\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 2s 291us/sample - loss: 0.3361 - acc: 0.8597\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 2s 304us/sample - loss: 0.3356 - acc: 0.8618\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 3s 322us/sample - loss: 0.3356 - acc: 0.8608\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 2s 306us/sample - loss: 0.3365 - acc: 0.8606\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 2s 282us/sample - loss: 0.3354 - acc: 0.8625\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 2s 286us/sample - loss: 0.3349 - acc: 0.8629\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 2s 283us/sample - loss: 0.3349 - acc: 0.8631\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 2s 291us/sample - loss: 0.3347 - acc: 0.8602\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 3s 334us/sample - loss: 0.3350 - acc: 0.8610\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 2s 299us/sample - loss: 0.3336 - acc: 0.8622\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 2s 308us/sample - loss: 0.3335 - acc: 0.8633\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 2s 259us/sample - loss: 0.3351 - acc: 0.8612\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 2s 254us/sample - loss: 0.3341 - acc: 0.8629\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 2s 256us/sample - loss: 0.3346 - acc: 0.8615\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 2s 257us/sample - loss: 0.3342 - acc: 0.8641\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 2s 291us/sample - loss: 0.3336 - acc: 0.8627\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 2s 258us/sample - loss: 0.3343 - acc: 0.8621\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 2s 269us/sample - loss: 0.3333 - acc: 0.8610\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 2s 250us/sample - loss: 0.3338 - acc: 0.8619\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 2s 248us/sample - loss: 0.3338 - acc: 0.8630\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 2s 252us/sample - loss: 0.3341 - acc: 0.8619\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 2s 275us/sample - loss: 0.3327 - acc: 0.8624\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 2s 254us/sample - loss: 0.3329 - acc: 0.8637\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 2s 290us/sample - loss: 0.3332 - acc: 0.8639\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 2s 259us/sample - loss: 0.3330 - acc: 0.8639\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 2s 267us/sample - loss: 0.3330 - acc: 0.8594\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 2s 286us/sample - loss: 0.3329 - acc: 0.8612\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 2s 264us/sample - loss: 0.3343 - acc: 0.8605\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 2s 264us/sample - loss: 0.3337 - acc: 0.8629\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 2s 255us/sample - loss: 0.3327 - acc: 0.8630\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 2s 282us/sample - loss: 0.3321 - acc: 0.8629\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 2s 268us/sample - loss: 0.3329 - acc: 0.8621\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 2s 233us/sample - loss: 0.3321 - acc: 0.8612\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 2s 209us/sample - loss: 0.3334 - acc: 0.8635\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 2s 209us/sample - loss: 0.3318 - acc: 0.8620\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 2s 210us/sample - loss: 0.3321 - acc: 0.8624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14d8e98a088>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(15, input_shape = (10, ), activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 104us/sample - loss: 0.3496 - acc: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34961445689201354, 0.859]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24859753],\n",
       "       [0.1005443 ],\n",
       "       [0.17100799],\n",
       "       [0.18345013],\n",
       "       [0.24051797]], dtype=float32)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9415    0\n",
       "6377    1\n",
       "8019    0\n",
       "7754    1\n",
       "4961    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24859753],\n",
       "       [0.1005443 ],\n",
       "       [0.17100799],\n",
       "       ...,\n",
       "       [0.00647864],\n",
       "       [0.42368752],\n",
       "       [0.07129672]], dtype=float32)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = np.asanyarray(y_predicted)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1005443], dtype=float32)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(y_predicted)):\n",
    "    if y_predicted[i] > 0.5:\n",
    "        y_predict.append(1)\n",
    "    else:\n",
    "        y_predict.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1518,   70],\n",
       "       [ 212,  200]], dtype=int64)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      1588\n",
      "           1       0.74      0.49      0.59       412\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.81      0.72      0.75      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling imbalanced data using Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7963 2037\n"
     ]
    }
   ],
   "source": [
    "class_0_counts, class_1_counts = data['Exited'].value_counts()\n",
    "print(class_0_counts, class_1_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_data = data[data['Exited'] == 0] #class 0 samples\n",
    "class_1_data = data[data['Exited'] == 1] #class 1 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7963, 11), (2037, 11))"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_0_data.shape, class_1_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling the 0 class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2037, 11)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_sampled_class_0 = class_0_data.sample(class_1_counts)\n",
    "under_sampled_class_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2037, 11) (2037, 11)\n"
     ]
    }
   ],
   "source": [
    "print(under_sampled_class_0.shape, class_1_data.shape)\n",
    "# both the dataset has same shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concating both the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4074, 11)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_sample_dataset = pd.concat([under_sampled_class_0, class_1_data], axis = 0)\n",
    "under_sample_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = under_sample_dataset.drop('Exited', axis = 1)\n",
    "y = under_sample_dataset['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting and training the model using ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3259/3259 [==============================] - 1s 280us/sample - loss: 0.6625 - acc: 0.5956\n",
      "Epoch 2/100\n",
      "3259/3259 [==============================] - 1s 215us/sample - loss: 0.6259 - acc: 0.6655\n",
      "Epoch 3/100\n",
      "3259/3259 [==============================] - 1s 268us/sample - loss: 0.6024 - acc: 0.6809\n",
      "Epoch 4/100\n",
      "3259/3259 [==============================] - 1s 270us/sample - loss: 0.5828 - acc: 0.6990\n",
      "Epoch 5/100\n",
      "3259/3259 [==============================] - 1s 221us/sample - loss: 0.5705 - acc: 0.7060\n",
      "Epoch 6/100\n",
      "3259/3259 [==============================] - 1s 219us/sample - loss: 0.5567 - acc: 0.7162\n",
      "Epoch 7/100\n",
      "3259/3259 [==============================] - 1s 231us/sample - loss: 0.5476 - acc: 0.7232\n",
      "Epoch 8/100\n",
      "3259/3259 [==============================] - 1s 262us/sample - loss: 0.5379 - acc: 0.7352\n",
      "Epoch 9/100\n",
      "3259/3259 [==============================] - 1s 222us/sample - loss: 0.5315 - acc: 0.7334\n",
      "Epoch 10/100\n",
      "3259/3259 [==============================] - 1s 212us/sample - loss: 0.5255 - acc: 0.7429\n",
      "Epoch 11/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.5232 - acc: 0.7419\n",
      "Epoch 12/100\n",
      "3259/3259 [==============================] - 1s 211us/sample - loss: 0.5190 - acc: 0.7472\n",
      "Epoch 13/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.5145 - acc: 0.7505\n",
      "Epoch 14/100\n",
      "3259/3259 [==============================] - 1s 215us/sample - loss: 0.5134 - acc: 0.7487\n",
      "Epoch 15/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.5092 - acc: 0.7496\n",
      "Epoch 16/100\n",
      "3259/3259 [==============================] - 1s 236us/sample - loss: 0.5094 - acc: 0.7576s - loss: 0.5007 - \n",
      "Epoch 17/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.5051 - acc: 0.7536\n",
      "Epoch 18/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.5035 - acc: 0.7597\n",
      "Epoch 19/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.5041 - acc: 0.7548\n",
      "Epoch 20/100\n",
      "3259/3259 [==============================] - 1s 218us/sample - loss: 0.5009 - acc: 0.7524\n",
      "Epoch 21/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.4999 - acc: 0.7579\n",
      "Epoch 22/100\n",
      "3259/3259 [==============================] - 1s 217us/sample - loss: 0.5012 - acc: 0.7576\n",
      "Epoch 23/100\n",
      "3259/3259 [==============================] - 1s 210us/sample - loss: 0.4967 - acc: 0.7585\n",
      "Epoch 24/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.4948 - acc: 0.7585\n",
      "Epoch 25/100\n",
      "3259/3259 [==============================] - 1s 281us/sample - loss: 0.4962 - acc: 0.7564\n",
      "Epoch 26/100\n",
      "3259/3259 [==============================] - 1s 270us/sample - loss: 0.4951 - acc: 0.7597\n",
      "Epoch 27/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.4931 - acc: 0.7604\n",
      "Epoch 28/100\n",
      "3259/3259 [==============================] - 1s 217us/sample - loss: 0.4930 - acc: 0.7579\n",
      "Epoch 29/100\n",
      "3259/3259 [==============================] - 1s 228us/sample - loss: 0.4929 - acc: 0.7579\n",
      "Epoch 30/100\n",
      "3259/3259 [==============================] - 1s 249us/sample - loss: 0.4903 - acc: 0.7600\n",
      "Epoch 31/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.4913 - acc: 0.7588\n",
      "Epoch 32/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.4891 - acc: 0.7613\n",
      "Epoch 33/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.4876 - acc: 0.7597\n",
      "Epoch 34/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.4903 - acc: 0.7613\n",
      "Epoch 35/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.4876 - acc: 0.7610\n",
      "Epoch 36/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.4877 - acc: 0.7613\n",
      "Epoch 37/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.4863 - acc: 0.7650\n",
      "Epoch 38/100\n",
      "3259/3259 [==============================] - 1s 246us/sample - loss: 0.4863 - acc: 0.7607\n",
      "Epoch 39/100\n",
      "3259/3259 [==============================] - 1s 233us/sample - loss: 0.4839 - acc: 0.7628\n",
      "Epoch 40/100\n",
      "3259/3259 [==============================] - 1s 215us/sample - loss: 0.4839 - acc: 0.7671\n",
      "Epoch 41/100\n",
      "3259/3259 [==============================] - 1s 224us/sample - loss: 0.4832 - acc: 0.7640\n",
      "Epoch 42/100\n",
      "3259/3259 [==============================] - 1s 254us/sample - loss: 0.4843 - acc: 0.7643\n",
      "Epoch 43/100\n",
      "3259/3259 [==============================] - 1s 260us/sample - loss: 0.4809 - acc: 0.7650\n",
      "Epoch 44/100\n",
      "3259/3259 [==============================] - 1s 273us/sample - loss: 0.4830 - acc: 0.7677\n",
      "Epoch 45/100\n",
      "3259/3259 [==============================] - 1s 260us/sample - loss: 0.4802 - acc: 0.7662\n",
      "Epoch 46/100\n",
      "3259/3259 [==============================] - 1s 298us/sample - loss: 0.4810 - acc: 0.7683\n",
      "Epoch 47/100\n",
      "3259/3259 [==============================] - 1s 275us/sample - loss: 0.4802 - acc: 0.7671\n",
      "Epoch 48/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.4791 - acc: 0.7708\n",
      "Epoch 49/100\n",
      "3259/3259 [==============================] - 1s 218us/sample - loss: 0.4809 - acc: 0.7732\n",
      "Epoch 50/100\n",
      "3259/3259 [==============================] - 1s 230us/sample - loss: 0.4786 - acc: 0.7650\n",
      "Epoch 51/100\n",
      "3259/3259 [==============================] - 1s 250us/sample - loss: 0.4792 - acc: 0.7686\n",
      "Epoch 52/100\n",
      "3259/3259 [==============================] - 1s 218us/sample - loss: 0.4787 - acc: 0.7683\n",
      "Epoch 53/100\n",
      "3259/3259 [==============================] - 1s 211us/sample - loss: 0.4791 - acc: 0.7680\n",
      "Epoch 54/100\n",
      "3259/3259 [==============================] - 1s 220us/sample - loss: 0.4784 - acc: 0.7696\n",
      "Epoch 55/100\n",
      "3259/3259 [==============================] - 1s 218us/sample - loss: 0.4787 - acc: 0.7653\n",
      "Epoch 56/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.4774 - acc: 0.7711\n",
      "Epoch 57/100\n",
      "3259/3259 [==============================] - 1s 211us/sample - loss: 0.4758 - acc: 0.7705\n",
      "Epoch 58/100\n",
      "3259/3259 [==============================] - 1s 218us/sample - loss: 0.4769 - acc: 0.7714\n",
      "Epoch 59/100\n",
      "3259/3259 [==============================] - 1s 211us/sample - loss: 0.4771 - acc: 0.7668\n",
      "Epoch 60/100\n",
      "3259/3259 [==============================] - 1s 209us/sample - loss: 0.4766 - acc: 0.7732\n",
      "Epoch 61/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.4768 - acc: 0.7668\n",
      "Epoch 62/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.4762 - acc: 0.7714\n",
      "Epoch 63/100\n",
      "3259/3259 [==============================] - 1s 209us/sample - loss: 0.4766 - acc: 0.7656\n",
      "Epoch 64/100\n",
      "3259/3259 [==============================] - 1s 211us/sample - loss: 0.4792 - acc: 0.7662\n",
      "Epoch 65/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.4766 - acc: 0.7708\n",
      "Epoch 66/100\n",
      "3259/3259 [==============================] - 1s 280us/sample - loss: 0.4760 - acc: 0.7668\n",
      "Epoch 67/100\n",
      "3259/3259 [==============================] - 1s 308us/sample - loss: 0.4751 - acc: 0.7705\n",
      "Epoch 68/100\n",
      "3259/3259 [==============================] - 1s 304us/sample - loss: 0.4750 - acc: 0.7696\n",
      "Epoch 69/100\n",
      "3259/3259 [==============================] - 1s 222us/sample - loss: 0.4764 - acc: 0.7656\n",
      "Epoch 70/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.4740 - acc: 0.7640\n",
      "Epoch 71/100\n",
      "3259/3259 [==============================] - 1s 225us/sample - loss: 0.4734 - acc: 0.7705\n",
      "Epoch 72/100\n",
      "3259/3259 [==============================] - 1s 251us/sample - loss: 0.4719 - acc: 0.7714\n",
      "Epoch 73/100\n",
      "3259/3259 [==============================] - 1s 217us/sample - loss: 0.4711 - acc: 0.7723\n",
      "Epoch 74/100\n",
      "3259/3259 [==============================] - 1s 219us/sample - loss: 0.4728 - acc: 0.7693\n",
      "Epoch 75/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.4739 - acc: 0.7662\n",
      "Epoch 76/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.4720 - acc: 0.7705\n",
      "Epoch 77/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.4716 - acc: 0.7699\n",
      "Epoch 78/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.4707 - acc: 0.7659\n",
      "Epoch 79/100\n",
      "3259/3259 [==============================] - 1s 216us/sample - loss: 0.4713 - acc: 0.7674\n",
      "Epoch 80/100\n",
      "3259/3259 [==============================] - 1s 209us/sample - loss: 0.4729 - acc: 0.7705\n",
      "Epoch 81/100\n",
      "3259/3259 [==============================] - 1s 210us/sample - loss: 0.4737 - acc: 0.7677\n",
      "Epoch 82/100\n",
      "3259/3259 [==============================] - 1s 207us/sample - loss: 0.4723 - acc: 0.7671\n",
      "Epoch 83/100\n",
      "3259/3259 [==============================] - 1s 219us/sample - loss: 0.4711 - acc: 0.7757\n",
      "Epoch 84/100\n",
      "3259/3259 [==============================] - 1s 209us/sample - loss: 0.4717 - acc: 0.7686\n",
      "Epoch 85/100\n",
      "3259/3259 [==============================] - 1s 206us/sample - loss: 0.4696 - acc: 0.7769\n",
      "Epoch 86/100\n",
      "3259/3259 [==============================] - 1s 211us/sample - loss: 0.4702 - acc: 0.7736\n",
      "Epoch 87/100\n",
      "3259/3259 [==============================] - 1s 248us/sample - loss: 0.4682 - acc: 0.7717\n",
      "Epoch 88/100\n",
      "3259/3259 [==============================] - 1s 231us/sample - loss: 0.4689 - acc: 0.7748\n",
      "Epoch 89/100\n",
      "3259/3259 [==============================] - 1s 273us/sample - loss: 0.4711 - acc: 0.7745\n",
      "Epoch 90/100\n",
      "3259/3259 [==============================] - 1s 243us/sample - loss: 0.4708 - acc: 0.7699\n",
      "Epoch 91/100\n",
      "3259/3259 [==============================] - 1s 206us/sample - loss: 0.4701 - acc: 0.7656\n",
      "Epoch 92/100\n",
      "3259/3259 [==============================] - 1s 209us/sample - loss: 0.4703 - acc: 0.7686\n",
      "Epoch 93/100\n",
      "3259/3259 [==============================] - 1s 223us/sample - loss: 0.4693 - acc: 0.7726\n",
      "Epoch 94/100\n",
      "3259/3259 [==============================] - 1s 250us/sample - loss: 0.4713 - acc: 0.7696\n",
      "Epoch 95/100\n",
      "3259/3259 [==============================] - 1s 214us/sample - loss: 0.4678 - acc: 0.7754\n",
      "Epoch 96/100\n",
      "3259/3259 [==============================] - 1s 218us/sample - loss: 0.4679 - acc: 0.7717\n",
      "Epoch 97/100\n",
      "3259/3259 [==============================] - 1s 209us/sample - loss: 0.4681 - acc: 0.7705\n",
      "Epoch 98/100\n",
      "3259/3259 [==============================] - 1s 211us/sample - loss: 0.4700 - acc: 0.7714\n",
      "Epoch 99/100\n",
      "3259/3259 [==============================] - 1s 211us/sample - loss: 0.4681 - acc: 0.7714\n",
      "Epoch 100/100\n",
      "3259/3259 [==============================] - 1s 211us/sample - loss: 0.4669 - acc: 0.7766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14d8ec59cc8>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(15, input_shape = (10, ), activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "815/815 [==============================] - 0s 192us/sample - loss: 0.4732 - acc: 0.7632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47321462346000903, 0.7631902]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the model and converting the output as 1 and 0 using 0.5 as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted = np.asanyarray(y_predicted)\n",
    "y_predict = []\n",
    "for i in range(len(y_predicted)):\n",
    "    if y_predicted[i] > 0.5:\n",
    "        y_predict.append(1)\n",
    "    else:\n",
    "        y_predict.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[328,  75],\n",
       "       [118, 294]], dtype=int64)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77       403\n",
      "           1       0.80      0.71      0.75       412\n",
      "\n",
      "    accuracy                           0.76       815\n",
      "   macro avg       0.77      0.76      0.76       815\n",
      "weighted avg       0.77      0.76      0.76       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the f1-score of  the classes 0 - (0.92) and 1 - (0.59) has changed to classes 0 - (0.77) and 1 - (0.75)..  \n",
    "So, overall f1 Score is better than the previous ANN model wihout handling imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Handling imbalanced data using Oversampling : Duplicate Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_0_counts, class_1_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7963, 11), (2037, 11))"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_0_data.shape, class_1_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the dataset equal in number randomly copying any dataset in class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7963, 11), (7963, 11))"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_sampled_class_1 = class_1_data.sample(class_0_counts, replace=True)\n",
    "class_0_data.shape, under_sampled_class_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatinating both the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15926, 11)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_sample_dataset = pd.concat([class_0_data, under_sampled_class_1], axis = 0)\n",
    "over_sample_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = over_sample_dataset.drop('Exited', axis = 1)\n",
    "y = over_sample_dataset['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the in train and test and executing the ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12740/12740 [==============================] - 3s 231us/sample - loss: 0.6199 - acc: 0.6571\n",
      "Epoch 2/100\n",
      "12740/12740 [==============================] - 3s 244us/sample - loss: 0.5698 - acc: 0.7049\n",
      "Epoch 3/100\n",
      "12740/12740 [==============================] - 3s 229us/sample - loss: 0.5409 - acc: 0.7254\n",
      "Epoch 4/100\n",
      "12740/12740 [==============================] - 3s 210us/sample - loss: 0.5216 - acc: 0.7418\n",
      "Epoch 5/100\n",
      "12740/12740 [==============================] - 3s 240us/sample - loss: 0.5103 - acc: 0.7451\n",
      "Epoch 6/100\n",
      "12740/12740 [==============================] - 3s 209us/sample - loss: 0.5008 - acc: 0.7513\n",
      "Epoch 7/100\n",
      "12740/12740 [==============================] - 3s 211us/sample - loss: 0.4940 - acc: 0.7546\n",
      "Epoch 8/100\n",
      "12740/12740 [==============================] - 3s 230us/sample - loss: 0.4894 - acc: 0.7554\n",
      "Epoch 9/100\n",
      "12740/12740 [==============================] - 3s 218us/sample - loss: 0.4862 - acc: 0.7596\n",
      "Epoch 10/100\n",
      "12740/12740 [==============================] - 3s 220us/sample - loss: 0.4843 - acc: 0.7575\n",
      "Epoch 11/100\n",
      "12740/12740 [==============================] - 3s 207us/sample - loss: 0.4825 - acc: 0.7622\n",
      "Epoch 12/100\n",
      "12740/12740 [==============================] - 3s 206us/sample - loss: 0.4802 - acc: 0.7626\n",
      "Epoch 13/100\n",
      "12740/12740 [==============================] - 3s 225us/sample - loss: 0.4768 - acc: 0.7644\n",
      "Epoch 14/100\n",
      "12740/12740 [==============================] - 3s 221us/sample - loss: 0.4772 - acc: 0.7630\n",
      "Epoch 15/100\n",
      "12740/12740 [==============================] - 3s 222us/sample - loss: 0.4747 - acc: 0.7633\n",
      "Epoch 16/100\n",
      "12740/12740 [==============================] - 3s 212us/sample - loss: 0.4737 - acc: 0.7667\n",
      "Epoch 17/100\n",
      "12740/12740 [==============================] - 3s 210us/sample - loss: 0.4721 - acc: 0.7692\n",
      "Epoch 18/100\n",
      "12740/12740 [==============================] - 3s 211us/sample - loss: 0.4710 - acc: 0.7672\n",
      "Epoch 19/100\n",
      "12740/12740 [==============================] - 3s 236us/sample - loss: 0.4698 - acc: 0.7722\n",
      "Epoch 20/100\n",
      "12740/12740 [==============================] - 3s 219us/sample - loss: 0.4687 - acc: 0.7724\n",
      "Epoch 21/100\n",
      "12740/12740 [==============================] - 3s 215us/sample - loss: 0.4686 - acc: 0.7755\n",
      "Epoch 22/100\n",
      "12740/12740 [==============================] - 3s 210us/sample - loss: 0.4672 - acc: 0.7703\n",
      "Epoch 23/100\n",
      "12740/12740 [==============================] - 3s 208us/sample - loss: 0.4661 - acc: 0.7739\n",
      "Epoch 24/100\n",
      "12740/12740 [==============================] - 3s 208us/sample - loss: 0.4647 - acc: 0.7747\n",
      "Epoch 25/100\n",
      "12740/12740 [==============================] - 3s 239us/sample - loss: 0.4627 - acc: 0.7735\n",
      "Epoch 26/100\n",
      "12740/12740 [==============================] - 3s 220us/sample - loss: 0.4621 - acc: 0.7753\n",
      "Epoch 27/100\n",
      "12740/12740 [==============================] - 3s 212us/sample - loss: 0.4629 - acc: 0.7768\n",
      "Epoch 28/100\n",
      "12740/12740 [==============================] - 3s 210us/sample - loss: 0.4603 - acc: 0.7766\n",
      "Epoch 29/100\n",
      "12740/12740 [==============================] - 3s 208us/sample - loss: 0.4603 - acc: 0.7777\n",
      "Epoch 30/100\n",
      "12740/12740 [==============================] - 3s 207us/sample - loss: 0.4585 - acc: 0.7794\n",
      "Epoch 31/100\n",
      "12740/12740 [==============================] - 3s 237us/sample - loss: 0.4571 - acc: 0.7805\n",
      "Epoch 32/100\n",
      "12740/12740 [==============================] - 3s 221us/sample - loss: 0.4569 - acc: 0.7787\n",
      "Epoch 33/100\n",
      "12740/12740 [==============================] - 3s 209us/sample - loss: 0.4559 - acc: 0.7799\n",
      "Epoch 34/100\n",
      "12740/12740 [==============================] - 3s 207us/sample - loss: 0.4547 - acc: 0.7811\n",
      "Epoch 35/100\n",
      "12740/12740 [==============================] - 3s 225us/sample - loss: 0.4528 - acc: 0.7815\n",
      "Epoch 36/100\n",
      "12740/12740 [==============================] - 3s 223us/sample - loss: 0.4530 - acc: 0.7859\n",
      "Epoch 37/100\n",
      "12740/12740 [==============================] - 3s 228us/sample - loss: 0.4505 - acc: 0.7851\n",
      "Epoch 38/100\n",
      "12740/12740 [==============================] - 3s 221us/sample - loss: 0.4510 - acc: 0.7827\n",
      "Epoch 39/100\n",
      "12740/12740 [==============================] - 3s 221us/sample - loss: 0.4501 - acc: 0.7833\n",
      "Epoch 40/100\n",
      "12740/12740 [==============================] - 3s 219us/sample - loss: 0.4490 - acc: 0.7868\n",
      "Epoch 41/100\n",
      "12740/12740 [==============================] - 3s 212us/sample - loss: 0.4499 - acc: 0.7838\n",
      "Epoch 42/100\n",
      "12740/12740 [==============================] - 3s 244us/sample - loss: 0.4479 - acc: 0.7877\n",
      "Epoch 43/100\n",
      "12740/12740 [==============================] - 3s 228us/sample - loss: 0.4477 - acc: 0.7868\n",
      "Epoch 44/100\n",
      "12740/12740 [==============================] - 3s 240us/sample - loss: 0.4471 - acc: 0.7871\n",
      "Epoch 45/100\n",
      "12740/12740 [==============================] - 3s 223us/sample - loss: 0.4452 - acc: 0.7840\n",
      "Epoch 46/100\n",
      "12740/12740 [==============================] - 3s 224us/sample - loss: 0.4451 - acc: 0.7849\n",
      "Epoch 47/100\n",
      "12740/12740 [==============================] - 3s 209us/sample - loss: 0.4449 - acc: 0.7879\n",
      "Epoch 48/100\n",
      "12740/12740 [==============================] - 3s 236us/sample - loss: 0.4446 - acc: 0.7870\n",
      "Epoch 49/100\n",
      "12740/12740 [==============================] - 3s 224us/sample - loss: 0.4441 - acc: 0.7898\n",
      "Epoch 50/100\n",
      "12740/12740 [==============================] - 3s 220us/sample - loss: 0.4433 - acc: 0.7869\n",
      "Epoch 51/100\n",
      "12740/12740 [==============================] - 3s 214us/sample - loss: 0.4426 - acc: 0.7884\n",
      "Epoch 52/100\n",
      "12740/12740 [==============================] - 3s 209us/sample - loss: 0.4420 - acc: 0.7909\n",
      "Epoch 53/100\n",
      "12740/12740 [==============================] - 3s 236us/sample - loss: 0.4422 - acc: 0.7875\n",
      "Epoch 54/100\n",
      "12740/12740 [==============================] - 3s 228us/sample - loss: 0.4404 - acc: 0.7874\n",
      "Epoch 55/100\n",
      "12740/12740 [==============================] - 3s 238us/sample - loss: 0.4402 - acc: 0.7916\n",
      "Epoch 56/100\n",
      "12740/12740 [==============================] - 3s 223us/sample - loss: 0.4410 - acc: 0.7907\n",
      "Epoch 57/100\n",
      "12740/12740 [==============================] - 3s 208us/sample - loss: 0.4405 - acc: 0.7901\n",
      "Epoch 58/100\n",
      "12740/12740 [==============================] - 3s 208us/sample - loss: 0.4403 - acc: 0.7900\n",
      "Epoch 59/100\n",
      "12740/12740 [==============================] - 3s 247us/sample - loss: 0.4396 - acc: 0.7888\n",
      "Epoch 60/100\n",
      "12740/12740 [==============================] - 3s 224us/sample - loss: 0.4395 - acc: 0.7889\n",
      "Epoch 61/100\n",
      "12740/12740 [==============================] - 3s 209us/sample - loss: 0.4390 - acc: 0.7900\n",
      "Epoch 62/100\n",
      "12740/12740 [==============================] - 3s 213us/sample - loss: 0.4388 - acc: 0.7899\n",
      "Epoch 63/100\n",
      "12740/12740 [==============================] - 3s 209us/sample - loss: 0.4386 - acc: 0.7889\n",
      "Epoch 64/100\n",
      "12740/12740 [==============================] - 3s 206us/sample - loss: 0.4378 - acc: 0.7896\n",
      "Epoch 65/100\n",
      "12740/12740 [==============================] - 3s 239us/sample - loss: 0.4378 - acc: 0.7892\n",
      "Epoch 66/100\n",
      "12740/12740 [==============================] - 3s 222us/sample - loss: 0.4388 - acc: 0.7923\n",
      "Epoch 67/100\n",
      "12740/12740 [==============================] - 3s 210us/sample - loss: 0.4370 - acc: 0.7905\n",
      "Epoch 68/100\n",
      "12740/12740 [==============================] - 3s 210us/sample - loss: 0.4371 - acc: 0.7911\n",
      "Epoch 69/100\n",
      "12740/12740 [==============================] - 3s 210us/sample - loss: 0.4380 - acc: 0.7899\n",
      "Epoch 70/100\n",
      "12740/12740 [==============================] - 3s 220us/sample - loss: 0.4365 - acc: 0.7901\n",
      "Epoch 71/100\n",
      "12740/12740 [==============================] - 3s 241us/sample - loss: 0.4369 - acc: 0.7905\n",
      "Epoch 72/100\n",
      "12740/12740 [==============================] - 3s 232us/sample - loss: 0.4372 - acc: 0.7911\n",
      "Epoch 73/100\n",
      "12740/12740 [==============================] - 3s 211us/sample - loss: 0.4362 - acc: 0.7926\n",
      "Epoch 74/100\n",
      "12740/12740 [==============================] - 3s 209us/sample - loss: 0.4365 - acc: 0.7928\n",
      "Epoch 75/100\n",
      "12740/12740 [==============================] - 3s 209us/sample - loss: 0.4363 - acc: 0.7907\n",
      "Epoch 76/100\n",
      "12740/12740 [==============================] - 3s 243us/sample - loss: 0.4357 - acc: 0.7925\n",
      "Epoch 77/100\n",
      "12740/12740 [==============================] - 3s 221us/sample - loss: 0.4360 - acc: 0.7932\n",
      "Epoch 78/100\n",
      "12740/12740 [==============================] - 3s 207us/sample - loss: 0.4361 - acc: 0.7938\n",
      "Epoch 79/100\n",
      "12740/12740 [==============================] - 3s 205us/sample - loss: 0.4349 - acc: 0.7945\n",
      "Epoch 80/100\n",
      "12740/12740 [==============================] - 3s 203us/sample - loss: 0.4359 - acc: 0.7925\n",
      "Epoch 81/100\n",
      "12740/12740 [==============================] - 3s 204us/sample - loss: 0.4347 - acc: 0.7962\n",
      "Epoch 82/100\n",
      "12740/12740 [==============================] - 3s 234us/sample - loss: 0.4352 - acc: 0.7925\n",
      "Epoch 83/100\n",
      "12740/12740 [==============================] - 3s 218us/sample - loss: 0.4346 - acc: 0.7928\n",
      "Epoch 84/100\n",
      "12740/12740 [==============================] - 3s 209us/sample - loss: 0.4357 - acc: 0.7951\n",
      "Epoch 85/100\n",
      "12740/12740 [==============================] - 3s 205us/sample - loss: 0.4344 - acc: 0.7935\n",
      "Epoch 86/100\n",
      "12740/12740 [==============================] - 3s 205us/sample - loss: 0.4344 - acc: 0.7943\n",
      "Epoch 87/100\n",
      "12740/12740 [==============================] - 3s 203us/sample - loss: 0.4344 - acc: 0.7959\n",
      "Epoch 88/100\n",
      "12740/12740 [==============================] - 3s 232us/sample - loss: 0.4336 - acc: 0.7941\n",
      "Epoch 89/100\n",
      "12740/12740 [==============================] - 3s 220us/sample - loss: 0.4341 - acc: 0.7954\n",
      "Epoch 90/100\n",
      "12740/12740 [==============================] - 3s 219us/sample - loss: 0.4333 - acc: 0.7922\n",
      "Epoch 91/100\n",
      "12740/12740 [==============================] - 3s 212us/sample - loss: 0.4335 - acc: 0.7944\n",
      "Epoch 92/100\n",
      "12740/12740 [==============================] - 3s 215us/sample - loss: 0.4337 - acc: 0.7943\n",
      "Epoch 93/100\n",
      "12740/12740 [==============================] - 3s 216us/sample - loss: 0.4326 - acc: 0.7945\n",
      "Epoch 94/100\n",
      "12740/12740 [==============================] - 4s 289us/sample - loss: 0.4331 - acc: 0.7944\n",
      "Epoch 95/100\n",
      "12740/12740 [==============================] - 3s 247us/sample - loss: 0.4325 - acc: 0.7945\n",
      "Epoch 96/100\n",
      "12740/12740 [==============================] - 3s 231us/sample - loss: 0.4332 - acc: 0.7932\n",
      "Epoch 97/100\n",
      "12740/12740 [==============================] - 3s 267us/sample - loss: 0.4341 - acc: 0.7941\n",
      "Epoch 98/100\n",
      "12740/12740 [==============================] - 3s 250us/sample - loss: 0.4323 - acc: 0.7938\n",
      "Epoch 99/100\n",
      "12740/12740 [==============================] - 3s 237us/sample - loss: 0.4326 - acc: 0.7949\n",
      "Epoch 100/100\n",
      "12740/12740 [==============================] - 3s 204us/sample - loss: 0.4327 - acc: 0.7947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14d900c3cc8>"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(15, input_shape = (10, ), activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3186/3186 [==============================] - 0s 80us/sample - loss: 0.4359 - acc: 0.7916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43592421715168256, 0.7915882]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the model and converting the output as 1 and 0 using 0.5 as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted = np.asanyarray(y_predicted)\n",
    "y_predict = []\n",
    "for i in range(len(y_predicted)):\n",
    "    if y_predicted[i] > 0.5:\n",
    "        y_predict.append(1)\n",
    "    else:\n",
    "        y_predict.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1294,  290],\n",
       "       [ 374, 1228]], dtype=int64)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1584\n",
      "           1       0.81      0.77      0.79      1602\n",
      "\n",
      "    accuracy                           0.79      3186\n",
      "   macro avg       0.79      0.79      0.79      3186\n",
      "weighted avg       0.79      0.79      0.79      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the f1-score of  the classes 0 - (0.92) and 1 - (0.59) has changed to classes 0 - (0.80) and 1 - (0.79)..  \n",
    "So, overall f1 Score is better than the previous ANN model wihout handling imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Handling imbalanced data using Oversampling : SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7963, 2037)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_0_counts, class_1_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Exited', axis = 1)\n",
    "y = data['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE uses KNN to make duplicate dataset which is better than randomly copying the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_data, y_data = smote.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7963\n",
       "0    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.value_counts()\n",
    "# both the classes data is same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the train and test sample and executing the ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12740/12740 [==============================] - 3s 240us/sample - loss: 0.6176 - acc: 0.6643\n",
      "Epoch 2/100\n",
      "12740/12740 [==============================] - 3s 248us/sample - loss: 0.5516 - acc: 0.7189\n",
      "Epoch 3/100\n",
      "12740/12740 [==============================] - 3s 261us/sample - loss: 0.5202 - acc: 0.7453\n",
      "Epoch 4/100\n",
      "12740/12740 [==============================] - 3s 235us/sample - loss: 0.5037 - acc: 0.7564\n",
      "Epoch 5/100\n",
      "12740/12740 [==============================] - 3s 221us/sample - loss: 0.4942 - acc: 0.7629\n",
      "Epoch 6/100\n",
      "12740/12740 [==============================] - 3s 219us/sample - loss: 0.4887 - acc: 0.7666\n",
      "Epoch 7/100\n",
      "12740/12740 [==============================] - 3s 223us/sample - loss: 0.4852 - acc: 0.7640\n",
      "Epoch 8/100\n",
      "12740/12740 [==============================] - 3s 248us/sample - loss: 0.4801 - acc: 0.7695\n",
      "Epoch 9/100\n",
      "12740/12740 [==============================] - 3s 237us/sample - loss: 0.4769 - acc: 0.7690\n",
      "Epoch 10/100\n",
      "12740/12740 [==============================] - 3s 235us/sample - loss: 0.4748 - acc: 0.7691\n",
      "Epoch 11/100\n",
      "12740/12740 [==============================] - 3s 225us/sample - loss: 0.4698 - acc: 0.7763\n",
      "Epoch 12/100\n",
      "12740/12740 [==============================] - 3s 224us/sample - loss: 0.4665 - acc: 0.7750\n",
      "Epoch 13/100\n",
      "12740/12740 [==============================] - 3s 227us/sample - loss: 0.4617 - acc: 0.7758\n",
      "Epoch 14/100\n",
      "12740/12740 [==============================] - 3s 264us/sample - loss: 0.4581 - acc: 0.7780\n",
      "Epoch 15/100\n",
      "12740/12740 [==============================] - 3s 246us/sample - loss: 0.4532 - acc: 0.7823\n",
      "Epoch 16/100\n",
      "12740/12740 [==============================] - 3s 225us/sample - loss: 0.4489 - acc: 0.7818\n",
      "Epoch 17/100\n",
      "12740/12740 [==============================] - 3s 226us/sample - loss: 0.4455 - acc: 0.7876\n",
      "Epoch 18/100\n",
      "12740/12740 [==============================] - 3s 226us/sample - loss: 0.4423 - acc: 0.7863\n",
      "Epoch 19/100\n",
      "12740/12740 [==============================] - 4s 300us/sample - loss: 0.4401 - acc: 0.7872\n",
      "Epoch 20/100\n",
      "12740/12740 [==============================] - 5s 377us/sample - loss: 0.4395 - acc: 0.7892\n",
      "Epoch 21/100\n",
      "12740/12740 [==============================] - 3s 239us/sample - loss: 0.4373 - acc: 0.7886\n",
      "Epoch 22/100\n",
      "12740/12740 [==============================] - 4s 314us/sample - loss: 0.4364 - acc: 0.7895\n",
      "Epoch 23/100\n",
      "12740/12740 [==============================] - 4s 312us/sample - loss: 0.4350 - acc: 0.7922\n",
      "Epoch 24/100\n",
      "12740/12740 [==============================] - 3s 255us/sample - loss: 0.4335 - acc: 0.7922\n",
      "Epoch 25/100\n",
      "12740/12740 [==============================] - 3s 232us/sample - loss: 0.4340 - acc: 0.7912\n",
      "Epoch 26/100\n",
      "12740/12740 [==============================] - 3s 232us/sample - loss: 0.4321 - acc: 0.7936\n",
      "Epoch 27/100\n",
      "12740/12740 [==============================] - 3s 227us/sample - loss: 0.4312 - acc: 0.7950\n",
      "Epoch 28/100\n",
      "12740/12740 [==============================] - 3s 261us/sample - loss: 0.4305 - acc: 0.7956\n",
      "Epoch 29/100\n",
      "12740/12740 [==============================] - 3s 239us/sample - loss: 0.4310 - acc: 0.7924\n",
      "Epoch 30/100\n",
      "12740/12740 [==============================] - ETA: 0s - loss: 0.4316 - acc: 0.793 - 3s 230us/sample - loss: 0.4312 - acc: 0.7939\n",
      "Epoch 31/100\n",
      "12740/12740 [==============================] - 3s 230us/sample - loss: 0.4305 - acc: 0.7951\n",
      "Epoch 32/100\n",
      "12740/12740 [==============================] - 3s 238us/sample - loss: 0.4292 - acc: 0.7947\n",
      "Epoch 33/100\n",
      "12740/12740 [==============================] - 3s 249us/sample - loss: 0.4288 - acc: 0.7934\n",
      "Epoch 34/100\n",
      "12740/12740 [==============================] - 3s 241us/sample - loss: 0.4297 - acc: 0.7937\n",
      "Epoch 35/100\n",
      "12740/12740 [==============================] - 3s 235us/sample - loss: 0.4294 - acc: 0.7943\n",
      "Epoch 36/100\n",
      "12740/12740 [==============================] - 3s 248us/sample - loss: 0.4284 - acc: 0.7958\n",
      "Epoch 37/100\n",
      "12740/12740 [==============================] - 3s 233us/sample - loss: 0.4285 - acc: 0.7955\n",
      "Epoch 38/100\n",
      "12740/12740 [==============================] - 3s 250us/sample - loss: 0.4277 - acc: 0.7968\n",
      "Epoch 39/100\n",
      "12740/12740 [==============================] - 3s 258us/sample - loss: 0.4280 - acc: 0.7953\n",
      "Epoch 40/100\n",
      "12740/12740 [==============================] - 3s 244us/sample - loss: 0.4269 - acc: 0.8012\n",
      "Epoch 41/100\n",
      "12740/12740 [==============================] - 3s 234us/sample - loss: 0.4279 - acc: 0.7980\n",
      "Epoch 42/100\n",
      "12740/12740 [==============================] - 3s 242us/sample - loss: 0.4279 - acc: 0.7961\n",
      "Epoch 43/100\n",
      "12740/12740 [==============================] - 3s 234us/sample - loss: 0.4265 - acc: 0.7975\n",
      "Epoch 44/100\n",
      "12740/12740 [==============================] - 3s 254us/sample - loss: 0.4275 - acc: 0.7951\n",
      "Epoch 45/100\n",
      "12740/12740 [==============================] - 3s 244us/sample - loss: 0.4272 - acc: 0.7955\n",
      "Epoch 46/100\n",
      "12740/12740 [==============================] - 3s 244us/sample - loss: 0.4262 - acc: 0.7976\n",
      "Epoch 47/100\n",
      "12740/12740 [==============================] - 3s 228us/sample - loss: 0.4250 - acc: 0.7957\n",
      "Epoch 48/100\n",
      "12740/12740 [==============================] - 3s 228us/sample - loss: 0.4261 - acc: 0.7984\n",
      "Epoch 49/100\n",
      "12740/12740 [==============================] - 3s 258us/sample - loss: 0.4254 - acc: 0.7986\n",
      "Epoch 50/100\n",
      "12740/12740 [==============================] - 3s 256us/sample - loss: 0.4254 - acc: 0.7982\n",
      "Epoch 51/100\n",
      "12740/12740 [==============================] - 3s 224us/sample - loss: 0.4245 - acc: 0.7949\n",
      "Epoch 52/100\n",
      "12740/12740 [==============================] - 3s 228us/sample - loss: 0.4243 - acc: 0.7976\n",
      "Epoch 53/100\n",
      "12740/12740 [==============================] - 3s 258us/sample - loss: 0.4258 - acc: 0.7958\n",
      "Epoch 54/100\n",
      "12740/12740 [==============================] - 3s 261us/sample - loss: 0.4250 - acc: 0.7969\n",
      "Epoch 55/100\n",
      "12740/12740 [==============================] - 3s 235us/sample - loss: 0.4248 - acc: 0.7989\n",
      "Epoch 56/100\n",
      "12740/12740 [==============================] - 3s 217us/sample - loss: 0.4248 - acc: 0.7991\n",
      "Epoch 57/100\n",
      "12740/12740 [==============================] - 3s 220us/sample - loss: 0.4238 - acc: 0.7965\n",
      "Epoch 58/100\n",
      "12740/12740 [==============================] - 3s 221us/sample - loss: 0.4241 - acc: 0.7981\n",
      "Epoch 59/100\n",
      "12740/12740 [==============================] - 3s 240us/sample - loss: 0.4241 - acc: 0.7969\n",
      "Epoch 60/100\n",
      "12740/12740 [==============================] - 3s 216us/sample - loss: 0.4248 - acc: 0.7996\n",
      "Epoch 61/100\n",
      "12740/12740 [==============================] - 3s 251us/sample - loss: 0.4236 - acc: 0.7973\n",
      "Epoch 62/100\n",
      "12740/12740 [==============================] - 3s 223us/sample - loss: 0.4239 - acc: 0.7966\n",
      "Epoch 63/100\n",
      "12740/12740 [==============================] - 3s 222us/sample - loss: 0.4251 - acc: 0.7958\n",
      "Epoch 64/100\n",
      "12740/12740 [==============================] - 3s 244us/sample - loss: 0.4236 - acc: 0.8009\n",
      "Epoch 65/100\n",
      "12740/12740 [==============================] - 3s 254us/sample - loss: 0.4236 - acc: 0.7998\n",
      "Epoch 66/100\n",
      "12740/12740 [==============================] - 3s 247us/sample - loss: 0.4242 - acc: 0.7962\n",
      "Epoch 67/100\n",
      "12740/12740 [==============================] - 3s 232us/sample - loss: 0.4236 - acc: 0.7979\n",
      "Epoch 68/100\n",
      "12740/12740 [==============================] - 3s 254us/sample - loss: 0.4243 - acc: 0.7991\n",
      "Epoch 69/100\n",
      "12740/12740 [==============================] - 3s 247us/sample - loss: 0.4224 - acc: 0.7979\n",
      "Epoch 70/100\n",
      "12740/12740 [==============================] - 5s 405us/sample - loss: 0.4229 - acc: 0.7985\n",
      "Epoch 71/100\n",
      "12740/12740 [==============================] - 4s 321us/sample - loss: 0.4238 - acc: 0.7966\n",
      "Epoch 72/100\n",
      "12740/12740 [==============================] - 3s 214us/sample - loss: 0.4217 - acc: 0.7987\n",
      "Epoch 73/100\n",
      "12740/12740 [==============================] - 3s 205us/sample - loss: 0.4224 - acc: 0.8017\n",
      "Epoch 74/100\n",
      "12740/12740 [==============================] - 3s 222us/sample - loss: 0.4231 - acc: 0.7985\n",
      "Epoch 75/100\n",
      "12740/12740 [==============================] - 3s 213us/sample - loss: 0.4225 - acc: 0.8007\n",
      "Epoch 76/100\n",
      "12740/12740 [==============================] - 3s 202us/sample - loss: 0.4212 - acc: 0.8006\n",
      "Epoch 77/100\n",
      "12740/12740 [==============================] - 2s 193us/sample - loss: 0.4212 - acc: 0.7997\n",
      "Epoch 78/100\n",
      "12740/12740 [==============================] - 3s 197us/sample - loss: 0.4214 - acc: 0.7977\n",
      "Epoch 79/100\n",
      "12740/12740 [==============================] - 2s 193us/sample - loss: 0.4231 - acc: 0.8011\n",
      "Epoch 80/100\n",
      "12740/12740 [==============================] - 3s 197us/sample - loss: 0.4213 - acc: 0.8014\n",
      "Epoch 81/100\n",
      "12740/12740 [==============================] - 3s 226us/sample - loss: 0.4210 - acc: 0.8004\n",
      "Epoch 82/100\n",
      "12740/12740 [==============================] - 3s 208us/sample - loss: 0.4209 - acc: 0.8024\n",
      "Epoch 83/100\n",
      "12740/12740 [==============================] - 2s 194us/sample - loss: 0.4220 - acc: 0.7985\n",
      "Epoch 84/100\n",
      "12740/12740 [==============================] - 2s 194us/sample - loss: 0.4218 - acc: 0.8002\n",
      "Epoch 85/100\n",
      "12740/12740 [==============================] - 3s 199us/sample - loss: 0.4205 - acc: 0.8010\n",
      "Epoch 86/100\n",
      "12740/12740 [==============================] - 3s 200us/sample - loss: 0.4211 - acc: 0.7995\n",
      "Epoch 87/100\n",
      "12740/12740 [==============================] - 3s 220us/sample - loss: 0.4206 - acc: 0.7984\n",
      "Epoch 88/100\n",
      "12740/12740 [==============================] - 3s 211us/sample - loss: 0.4207 - acc: 0.7995\n",
      "Epoch 89/100\n",
      "12740/12740 [==============================] - 3s 230us/sample - loss: 0.4204 - acc: 0.8014\n",
      "Epoch 90/100\n",
      "12740/12740 [==============================] - 3s 212us/sample - loss: 0.4206 - acc: 0.7992\n",
      "Epoch 91/100\n",
      "12740/12740 [==============================] - 3s 221us/sample - loss: 0.4204 - acc: 0.8002\n",
      "Epoch 92/100\n",
      "12740/12740 [==============================] - 3s 242us/sample - loss: 0.4198 - acc: 0.8012\n",
      "Epoch 93/100\n",
      "12740/12740 [==============================] - 3s 243us/sample - loss: 0.4206 - acc: 0.7999\n",
      "Epoch 94/100\n",
      "12740/12740 [==============================] - 3s 231us/sample - loss: 0.4188 - acc: 0.8028\n",
      "Epoch 95/100\n",
      "12740/12740 [==============================] - 3s 229us/sample - loss: 0.4196 - acc: 0.8005\n",
      "Epoch 96/100\n",
      "12740/12740 [==============================] - 3s 221us/sample - loss: 0.4198 - acc: 0.8008\n",
      "Epoch 97/100\n",
      "12740/12740 [==============================] - 3s 221us/sample - loss: 0.4198 - acc: 0.8031\n",
      "Epoch 98/100\n",
      "12740/12740 [==============================] - 3s 250us/sample - loss: 0.4197 - acc: 0.7999\n",
      "Epoch 99/100\n",
      "12740/12740 [==============================] - 3s 229us/sample - loss: 0.4190 - acc: 0.8031\n",
      "Epoch 100/100\n",
      "12740/12740 [==============================] - 3s 227us/sample - loss: 0.4196 - acc: 0.8009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14d914a5a48>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.2, random_state = 43)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(15, input_shape = (10, ), activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3186/3186 [==============================] - 0s 88us/sample - loss: 0.4299 - acc: 0.7982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42990752972302315, 0.7981795]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the model and converting the output as 1 and 0 using 0.5 as threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted = np.asanyarray(y_predicted)\n",
    "y_predict = []\n",
    "for i in range(len(y_predicted)):\n",
    "    if y_predicted[i] > 0.5:\n",
    "        y_predict.append(1)\n",
    "    else:\n",
    "        y_predict.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1302,  295],\n",
       "       [ 348, 1241]], dtype=int64)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      1597\n",
      "           1       0.81      0.78      0.79      1589\n",
      "\n",
      "    accuracy                           0.80      3186\n",
      "   macro avg       0.80      0.80      0.80      3186\n",
      "weighted avg       0.80      0.80      0.80      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the f1-score of  the classes 0 - (0.92) and 1 - (0.59) has changed to classes 0 - (0.80) and 1 - (0.79)..  \n",
    "So, overall f1 Score is better than the previous ANN model wihout handling imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Handling imbalanced data using Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Exited', axis = 1)\n",
    "y = data['Exited']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7963, 11), (2037, 11))"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_0_data.shape, class_1_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual count 3.9091801669121256\n",
      "Round of count 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual count\", (7963/2037))\n",
    "print(\"Round of count\", round(7963/2037))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is approximately in ratio of 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now taking the dataset of class 0 and class 1 and making them equal in examples by dividing the training set in same  \n",
    "length as test data and creaing different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Funtion to make different classes of dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_class_of_same_training_and_testing_dataset(start_index, end_index):\n",
    "    dataset_ = pd.concat([class_0_data[start_index:end_index], class_1_data], axis = 0)\n",
    "    X_train = dataset_.drop('Exited', axis = 1)\n",
    "    y_train = dataset_['Exited']\n",
    "    return X_train, y_train\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating 4 different datset classes of same number of both same training and testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, y_train1 = creating_class_of_same_training_and_testing_dataset(0,2037)\n",
    "X_train2, y_train2 = creating_class_of_same_training_and_testing_dataset(2037,4074)\n",
    "X_train3, y_train3 = creating_class_of_same_training_and_testing_dataset(4074,6111)\n",
    "X_train4, y_train4 = creating_class_of_same_training_and_testing_dataset(6111,7964)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4074, 10), (2000, 10))"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4074/4074 [==============================] - 1s 299us/sample - loss: 0.6613 - acc: 0.6073\n",
      "Epoch 2/100\n",
      "4074/4074 [==============================] - 1s 258us/sample - loss: 0.6173 - acc: 0.6674\n",
      "Epoch 3/100\n",
      "4074/4074 [==============================] - 1s 245us/sample - loss: 0.5909 - acc: 0.6969\n",
      "Epoch 4/100\n",
      "4074/4074 [==============================] - 1s 256us/sample - loss: 0.5671 - acc: 0.7106\n",
      "Epoch 5/100\n",
      "4074/4074 [==============================] - 1s 295us/sample - loss: 0.5484 - acc: 0.7219\n",
      "Epoch 6/100\n",
      "4074/4074 [==============================] - 1s 232us/sample - loss: 0.5338 - acc: 0.7315\n",
      "Epoch 7/100\n",
      "4074/4074 [==============================] - 1s 241us/sample - loss: 0.5232 - acc: 0.7435\n",
      "Epoch 8/100\n",
      "4074/4074 [==============================] - 1s 270us/sample - loss: 0.5175 - acc: 0.7410\n",
      "Epoch 9/100\n",
      "4074/4074 [==============================] - 1s 230us/sample - loss: 0.5129 - acc: 0.7467\n",
      "Epoch 10/100\n",
      "4074/4074 [==============================] - 1s 229us/sample - loss: 0.5063 - acc: 0.7536\n",
      "Epoch 11/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.5031 - acc: 0.7516\n",
      "Epoch 12/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4995 - acc: 0.7509\n",
      "Epoch 13/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4961 - acc: 0.7550\n",
      "Epoch 14/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4932 - acc: 0.7570\n",
      "Epoch 15/100\n",
      "4074/4074 [==============================] - 1s 240us/sample - loss: 0.4899 - acc: 0.7587\n",
      "Epoch 16/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4871 - acc: 0.7614\n",
      "Epoch 17/100\n",
      "4074/4074 [==============================] - 1s 238us/sample - loss: 0.4827 - acc: 0.7604\n",
      "Epoch 18/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4826 - acc: 0.7595\n",
      "Epoch 19/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4807 - acc: 0.7641\n",
      "Epoch 20/100\n",
      "4074/4074 [==============================] - 1s 238us/sample - loss: 0.4781 - acc: 0.7617\n",
      "Epoch 21/100\n",
      "4074/4074 [==============================] - 1s 287us/sample - loss: 0.4761 - acc: 0.7626\n",
      "Epoch 22/100\n",
      "4074/4074 [==============================] - 1s 248us/sample - loss: 0.4748 - acc: 0.7668\n",
      "Epoch 23/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4739 - acc: 0.7680\n",
      "Epoch 24/100\n",
      "4074/4074 [==============================] - 1s 245us/sample - loss: 0.4715 - acc: 0.7678\n",
      "Epoch 25/100\n",
      "4074/4074 [==============================] - 1s 253us/sample - loss: 0.4705 - acc: 0.7710\n",
      "Epoch 26/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4696 - acc: 0.7668\n",
      "Epoch 27/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4679 - acc: 0.7705\n",
      "Epoch 28/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4673 - acc: 0.7727\n",
      "Epoch 29/100\n",
      "4074/4074 [==============================] - 1s 242us/sample - loss: 0.4649 - acc: 0.7698\n",
      "Epoch 30/100\n",
      "4074/4074 [==============================] - 1s 246us/sample - loss: 0.4635 - acc: 0.7737\n",
      "Epoch 31/100\n",
      "4074/4074 [==============================] - 1s 241us/sample - loss: 0.4624 - acc: 0.7695\n",
      "Epoch 32/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4625 - acc: 0.7737\n",
      "Epoch 33/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4597 - acc: 0.7734\n",
      "Epoch 34/100\n",
      "4074/4074 [==============================] - 1s 245us/sample - loss: 0.4605 - acc: 0.7734\n",
      "Epoch 35/100\n",
      "4074/4074 [==============================] - 1s 280us/sample - loss: 0.4594 - acc: 0.7744\n",
      "Epoch 36/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4591 - acc: 0.7744\n",
      "Epoch 37/100\n",
      "4074/4074 [==============================] - 1s 297us/sample - loss: 0.4584 - acc: 0.7808\n",
      "Epoch 38/100\n",
      "4074/4074 [==============================] - 1s 258us/sample - loss: 0.4591 - acc: 0.7754\n",
      "Epoch 39/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4566 - acc: 0.7761\n",
      "Epoch 40/100\n",
      "4074/4074 [==============================] - 1s 243us/sample - loss: 0.4559 - acc: 0.7730\n",
      "Epoch 41/100\n",
      "4074/4074 [==============================] - 1s 250us/sample - loss: 0.4570 - acc: 0.7707\n",
      "Epoch 42/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4555 - acc: 0.7754\n",
      "Epoch 43/100\n",
      "4074/4074 [==============================] - 1s 226us/sample - loss: 0.4559 - acc: 0.7722\n",
      "Epoch 44/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4534 - acc: 0.7744\n",
      "Epoch 45/100\n",
      "4074/4074 [==============================] - 1s 226us/sample - loss: 0.4534 - acc: 0.7752\n",
      "Epoch 46/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4533 - acc: 0.7808\n",
      "Epoch 47/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4537 - acc: 0.7727\n",
      "Epoch 48/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4505 - acc: 0.7747\n",
      "Epoch 49/100\n",
      "4074/4074 [==============================] - 1s 226us/sample - loss: 0.4527 - acc: 0.7705\n",
      "Epoch 50/100\n",
      "4074/4074 [==============================] - 1s 226us/sample - loss: 0.4504 - acc: 0.7769\n",
      "Epoch 51/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4514 - acc: 0.7769\n",
      "Epoch 52/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4513 - acc: 0.7766\n",
      "Epoch 53/100\n",
      "4074/4074 [==============================] - 1s 277us/sample - loss: 0.4512 - acc: 0.7693\n",
      "Epoch 54/100\n",
      "4074/4074 [==============================] - 1s 279us/sample - loss: 0.4510 - acc: 0.7739\n",
      "Epoch 55/100\n",
      "4074/4074 [==============================] - 1s 224us/sample - loss: 0.4503 - acc: 0.7752\n",
      "Epoch 56/100\n",
      "4074/4074 [==============================] - 1s 221us/sample - loss: 0.4505 - acc: 0.7739\n",
      "Epoch 57/100\n",
      "4074/4074 [==============================] - 1s 282us/sample - loss: 0.4502 - acc: 0.7712\n",
      "Epoch 58/100\n",
      "4074/4074 [==============================] - 1s 280us/sample - loss: 0.4493 - acc: 0.7754\n",
      "Epoch 59/100\n",
      "4074/4074 [==============================] - 1s 268us/sample - loss: 0.4481 - acc: 0.7732\n",
      "Epoch 60/100\n",
      "4074/4074 [==============================] - ETA: 0s - loss: 0.4485 - acc: 0.774 - 1s 265us/sample - loss: 0.4487 - acc: 0.7747\n",
      "Epoch 61/100\n",
      "4074/4074 [==============================] - 1s 269us/sample - loss: 0.4480 - acc: 0.7732\n",
      "Epoch 62/100\n",
      "4074/4074 [==============================] - 1s 275us/sample - loss: 0.4476 - acc: 0.7757\n",
      "Epoch 63/100\n",
      "4074/4074 [==============================] - 1s 273us/sample - loss: 0.4477 - acc: 0.7761\n",
      "Epoch 64/100\n",
      "4074/4074 [==============================] - 1s 272us/sample - loss: 0.4478 - acc: 0.7766\n",
      "Epoch 65/100\n",
      "4074/4074 [==============================] - 1s 269us/sample - loss: 0.4485 - acc: 0.7766\n",
      "Epoch 66/100\n",
      "4074/4074 [==============================] - 1s 275us/sample - loss: 0.4463 - acc: 0.7749\n",
      "Epoch 67/100\n",
      "4074/4074 [==============================] - 1s 279us/sample - loss: 0.4461 - acc: 0.7808\n",
      "Epoch 68/100\n",
      "4074/4074 [==============================] - 1s 332us/sample - loss: 0.4474 - acc: 0.7793\n",
      "Epoch 69/100\n",
      "4074/4074 [==============================] - 1s 293us/sample - loss: 0.4478 - acc: 0.7771\n",
      "Epoch 70/100\n",
      "4074/4074 [==============================] - 1s 265us/sample - loss: 0.4466 - acc: 0.7742\n",
      "Epoch 71/100\n",
      "4074/4074 [==============================] - 1s 300us/sample - loss: 0.4492 - acc: 0.7776\n",
      "Epoch 72/100\n",
      "4074/4074 [==============================] - 1s 277us/sample - loss: 0.4471 - acc: 0.7747\n",
      "Epoch 73/100\n",
      "4074/4074 [==============================] - 1s 270us/sample - loss: 0.4470 - acc: 0.7833\n",
      "Epoch 74/100\n",
      "4074/4074 [==============================] - 1s 269us/sample - loss: 0.4458 - acc: 0.7747\n",
      "Epoch 75/100\n",
      "4074/4074 [==============================] - 1s 269us/sample - loss: 0.4465 - acc: 0.7784\n",
      "Epoch 76/100\n",
      "4074/4074 [==============================] - 1s 279us/sample - loss: 0.4461 - acc: 0.7796\n",
      "Epoch 77/100\n",
      "4074/4074 [==============================] - 1s 276us/sample - loss: 0.4475 - acc: 0.7722\n",
      "Epoch 78/100\n",
      "4074/4074 [==============================] - ETA: 0s - loss: 0.4422 - acc: 0.779 - 1s 275us/sample - loss: 0.4440 - acc: 0.7784\n",
      "Epoch 79/100\n",
      "4074/4074 [==============================] - 1s 271us/sample - loss: 0.4455 - acc: 0.7749\n",
      "Epoch 80/100\n",
      "4074/4074 [==============================] - 1s 272us/sample - loss: 0.4462 - acc: 0.7771\n",
      "Epoch 81/100\n",
      "4074/4074 [==============================] - 1s 280us/sample - loss: 0.4441 - acc: 0.7747\n",
      "Epoch 82/100\n",
      "4074/4074 [==============================] - 1s 329us/sample - loss: 0.4443 - acc: 0.7781\n",
      "Epoch 83/100\n",
      "4074/4074 [==============================] - 1s 293us/sample - loss: 0.4447 - acc: 0.7757\n",
      "Epoch 84/100\n",
      "4074/4074 [==============================] - 1s 273us/sample - loss: 0.4445 - acc: 0.7757\n",
      "Epoch 85/100\n",
      "4074/4074 [==============================] - 1s 341us/sample - loss: 0.4435 - acc: 0.7747\n",
      "Epoch 86/100\n",
      "4074/4074 [==============================] - 1s 312us/sample - loss: 0.4446 - acc: 0.7734\n",
      "Epoch 87/100\n",
      "4074/4074 [==============================] - 1s 297us/sample - loss: 0.4446 - acc: 0.7754\n",
      "Epoch 88/100\n",
      "4074/4074 [==============================] - 1s 300us/sample - loss: 0.4432 - acc: 0.7788s - loss: 0.4427 - acc: 0.779\n",
      "Epoch 89/100\n",
      "4074/4074 [==============================] - 1s 302us/sample - loss: 0.4434 - acc: 0.7779\n",
      "Epoch 90/100\n",
      "4074/4074 [==============================] - 1s 298us/sample - loss: 0.4437 - acc: 0.7806\n",
      "Epoch 91/100\n",
      "4074/4074 [==============================] - 1s 302us/sample - loss: 0.4444 - acc: 0.7764\n",
      "Epoch 92/100\n",
      "4074/4074 [==============================] - 1s 303us/sample - loss: 0.4437 - acc: 0.7774\n",
      "Epoch 93/100\n",
      "4074/4074 [==============================] - 1s 303us/sample - loss: 0.4424 - acc: 0.7779\n",
      "Epoch 94/100\n",
      "4074/4074 [==============================] - 1s 317us/sample - loss: 0.4419 - acc: 0.7847\n",
      "Epoch 95/100\n",
      "4074/4074 [==============================] - 1s 347us/sample - loss: 0.4431 - acc: 0.7771\n",
      "Epoch 96/100\n",
      "4074/4074 [==============================] - 1s 329us/sample - loss: 0.4425 - acc: 0.7806\n",
      "Epoch 97/100\n",
      "4074/4074 [==============================] - 1s 302us/sample - loss: 0.4432 - acc: 0.7764\n",
      "Epoch 98/100\n",
      "4074/4074 [==============================] - 2s 379us/sample - loss: 0.4410 - acc: 0.7781\n",
      "Epoch 99/100\n",
      "4074/4074 [==============================] - 1s 321us/sample - loss: 0.4414 - acc: 0.7811\n",
      "Epoch 100/100\n",
      "4074/4074 [==============================] - 1s 307us/sample - loss: 0.4421 - acc: 0.7793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14d91ab4988>"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(15, input_shape = (10, ), activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train1, y_train1, epochs=100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 177us/sample - loss: 0.4275 - acc: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4274610075950623, 0.8125]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_1 = model.predict(X_test)\n",
    "y_predicted_1 = np.asanyarray(y_predicted_1)\n",
    "y_predict_1 = []\n",
    "for i in range(len(y_predicted_1)):\n",
    "    if y_predicted_1[i] > 0.5:\n",
    "        y_predict_1.append(1)\n",
    "    else:\n",
    "        y_predict_1.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88      1588\n",
      "           1       0.53      0.70      0.61       412\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.73      0.77      0.74      2000\n",
      "weighted avg       0.84      0.81      0.82      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 2nd class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4074, 10), (2000, 10))"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4074/4074 [==============================] - 2s 395us/sample - loss: 0.7219 - acc: 0.5712\n",
      "Epoch 2/100\n",
      "4074/4074 [==============================] - 1s 313us/sample - loss: 0.6426 - acc: 0.6284\n",
      "Epoch 3/100\n",
      "4074/4074 [==============================] - 1s 348us/sample - loss: 0.6217 - acc: 0.6524\n",
      "Epoch 4/100\n",
      "4074/4074 [==============================] - 1s 351us/sample - loss: 0.6054 - acc: 0.6647\n",
      "Epoch 5/100\n",
      "4074/4074 [==============================] - 1s 331us/sample - loss: 0.5891 - acc: 0.6848\n",
      "Epoch 6/100\n",
      "4074/4074 [==============================] - 1s 309us/sample - loss: 0.5756 - acc: 0.6949\n",
      "Epoch 7/100\n",
      "4074/4074 [==============================] - 1s 345us/sample - loss: 0.5623 - acc: 0.7089\n",
      "Epoch 8/100\n",
      "4074/4074 [==============================] - 1s 332us/sample - loss: 0.5472 - acc: 0.7236\n",
      "Epoch 9/100\n",
      "4074/4074 [==============================] - 1s 313us/sample - loss: 0.5372 - acc: 0.7324\n",
      "Epoch 10/100\n",
      "4074/4074 [==============================] - 1s 314us/sample - loss: 0.5271 - acc: 0.7305\n",
      "Epoch 11/100\n",
      "4074/4074 [==============================] - 1s 309us/sample - loss: 0.5186 - acc: 0.7378\n",
      "Epoch 12/100\n",
      "4074/4074 [==============================] - 1s 306us/sample - loss: 0.5103 - acc: 0.7415\n",
      "Epoch 13/100\n",
      "4074/4074 [==============================] - 1s 313us/sample - loss: 0.5042 - acc: 0.7514\n",
      "Epoch 14/100\n",
      "4074/4074 [==============================] - 1s 317us/sample - loss: 0.4987 - acc: 0.7514\n",
      "Epoch 15/100\n",
      "4074/4074 [==============================] - 1s 334us/sample - loss: 0.4976 - acc: 0.7541\n",
      "Epoch 16/100\n",
      "4074/4074 [==============================] - 1s 349us/sample - loss: 0.4928 - acc: 0.7553\n",
      "Epoch 17/100\n",
      "4074/4074 [==============================] - 1s 331us/sample - loss: 0.4902 - acc: 0.7592\n",
      "Epoch 18/100\n",
      "4074/4074 [==============================] - 1s 345us/sample - loss: 0.4883 - acc: 0.7577\n",
      "Epoch 19/100\n",
      "4074/4074 [==============================] - 2s 385us/sample - loss: 0.4847 - acc: 0.7626\n",
      "Epoch 20/100\n",
      "4074/4074 [==============================] - 1s 334us/sample - loss: 0.4825 - acc: 0.7587\n",
      "Epoch 21/100\n",
      "4074/4074 [==============================] - 1s 328us/sample - loss: 0.4828 - acc: 0.7619\n",
      "Epoch 22/100\n",
      "4074/4074 [==============================] - 1s 320us/sample - loss: 0.4827 - acc: 0.7612\n",
      "Epoch 23/100\n",
      "4074/4074 [==============================] - 1s 313us/sample - loss: 0.4776 - acc: 0.7612\n",
      "Epoch 24/100\n",
      "4074/4074 [==============================] - 1s 329us/sample - loss: 0.4772 - acc: 0.7695\n",
      "Epoch 25/100\n",
      "4074/4074 [==============================] - 1s 315us/sample - loss: 0.4759 - acc: 0.7656\n",
      "Epoch 26/100\n",
      "4074/4074 [==============================] - 1s 317us/sample - loss: 0.4753 - acc: 0.7661\n",
      "Epoch 27/100\n",
      "4074/4074 [==============================] - 1s 347us/sample - loss: 0.4751 - acc: 0.7671\n",
      "Epoch 28/100\n",
      "4074/4074 [==============================] - 2s 377us/sample - loss: 0.4731 - acc: 0.7663s - loss: 0.\n",
      "Epoch 29/100\n",
      "4074/4074 [==============================] - 1s 333us/sample - loss: 0.4744 - acc: 0.7663\n",
      "Epoch 30/100\n",
      "4074/4074 [==============================] - 1s 315us/sample - loss: 0.4712 - acc: 0.7732\n",
      "Epoch 31/100\n",
      "4074/4074 [==============================] - 1s 345us/sample - loss: 0.4715 - acc: 0.7722\n",
      "Epoch 32/100\n",
      "4074/4074 [==============================] - 1s 314us/sample - loss: 0.4692 - acc: 0.7732\n",
      "Epoch 33/100\n",
      "4074/4074 [==============================] - 1s 326us/sample - loss: 0.4683 - acc: 0.7661\n",
      "Epoch 34/100\n",
      "4074/4074 [==============================] - 1s 312us/sample - loss: 0.4697 - acc: 0.7749\n",
      "Epoch 35/100\n",
      "4074/4074 [==============================] - 1s 319us/sample - loss: 0.4666 - acc: 0.7761\n",
      "Epoch 36/100\n",
      "4074/4074 [==============================] - 1s 319us/sample - loss: 0.4669 - acc: 0.7739\n",
      "Epoch 37/100\n",
      "4074/4074 [==============================] - 1s 319us/sample - loss: 0.4655 - acc: 0.7754\n",
      "Epoch 38/100\n",
      "4074/4074 [==============================] - 1s 314us/sample - loss: 0.4679 - acc: 0.7727\n",
      "Epoch 39/100\n",
      "4074/4074 [==============================] - 1s 345us/sample - loss: 0.4632 - acc: 0.7739\n",
      "Epoch 40/100\n",
      "4074/4074 [==============================] - 1s 356us/sample - loss: 0.4635 - acc: 0.7754\n",
      "Epoch 41/100\n",
      "4074/4074 [==============================] - 1s 337us/sample - loss: 0.4640 - acc: 0.7742\n",
      "Epoch 42/100\n",
      "4074/4074 [==============================] - 1s 350us/sample - loss: 0.4619 - acc: 0.7749\n",
      "Epoch 43/100\n",
      "4074/4074 [==============================] - 1s 341us/sample - loss: 0.4614 - acc: 0.7803\n",
      "Epoch 44/100\n",
      "4074/4074 [==============================] - 1s 325us/sample - loss: 0.4623 - acc: 0.7769\n",
      "Epoch 45/100\n",
      "4074/4074 [==============================] - 1s 320us/sample - loss: 0.4601 - acc: 0.7784\n",
      "Epoch 46/100\n",
      "4074/4074 [==============================] - 1s 333us/sample - loss: 0.4619 - acc: 0.7774\n",
      "Epoch 47/100\n",
      "4074/4074 [==============================] - 1s 295us/sample - loss: 0.4599 - acc: 0.7779\n",
      "Epoch 48/100\n",
      "4074/4074 [==============================] - 1s 285us/sample - loss: 0.4598 - acc: 0.7737\n",
      "Epoch 49/100\n",
      "4074/4074 [==============================] - 1s 297us/sample - loss: 0.4606 - acc: 0.7791\n",
      "Epoch 50/100\n",
      "4074/4074 [==============================] - 1s 287us/sample - loss: 0.4574 - acc: 0.7791\n",
      "Epoch 51/100\n",
      "4074/4074 [==============================] - 1s 346us/sample - loss: 0.4578 - acc: 0.7813\n",
      "Epoch 52/100\n",
      "4074/4074 [==============================] - 1s 335us/sample - loss: 0.4586 - acc: 0.7798\n",
      "Epoch 53/100\n",
      "4074/4074 [==============================] - 1s 287us/sample - loss: 0.4577 - acc: 0.7840\n",
      "Epoch 54/100\n",
      "4074/4074 [==============================] - 1s 308us/sample - loss: 0.4570 - acc: 0.7815\n",
      "Epoch 55/100\n",
      "4074/4074 [==============================] - 1s 294us/sample - loss: 0.4575 - acc: 0.7796\n",
      "Epoch 56/100\n",
      "4074/4074 [==============================] - 1s 278us/sample - loss: 0.4574 - acc: 0.7811\n",
      "Epoch 57/100\n",
      "4074/4074 [==============================] - 1s 277us/sample - loss: 0.4570 - acc: 0.7813\n",
      "Epoch 58/100\n",
      "4074/4074 [==============================] - 1s 277us/sample - loss: 0.4549 - acc: 0.7784\n",
      "Epoch 59/100\n",
      "4074/4074 [==============================] - 1s 274us/sample - loss: 0.4572 - acc: 0.7788\n",
      "Epoch 60/100\n",
      "4074/4074 [==============================] - 1s 275us/sample - loss: 0.4542 - acc: 0.7803\n",
      "Epoch 61/100\n",
      "4074/4074 [==============================] - 1s 282us/sample - loss: 0.4558 - acc: 0.7820\n",
      "Epoch 62/100\n",
      "4074/4074 [==============================] - 1s 275us/sample - loss: 0.4556 - acc: 0.7801\n",
      "Epoch 63/100\n",
      "4074/4074 [==============================] - 1s 276us/sample - loss: 0.4557 - acc: 0.7842\n",
      "Epoch 64/100\n",
      "4074/4074 [==============================] - 1s 287us/sample - loss: 0.4554 - acc: 0.7820\n",
      "Epoch 65/100\n",
      "4074/4074 [==============================] - 1s 330us/sample - loss: 0.4547 - acc: 0.7815\n",
      "Epoch 66/100\n",
      "4074/4074 [==============================] - 1s 291us/sample - loss: 0.4539 - acc: 0.7830\n",
      "Epoch 67/100\n",
      "4074/4074 [==============================] - 1s 275us/sample - loss: 0.4537 - acc: 0.7818\n",
      "Epoch 68/100\n",
      "4074/4074 [==============================] - 1s 320us/sample - loss: 0.4542 - acc: 0.7788\n",
      "Epoch 69/100\n",
      "4074/4074 [==============================] - 1s 287us/sample - loss: 0.4530 - acc: 0.7823s - loss: \n",
      "Epoch 70/100\n",
      "4074/4074 [==============================] - 1s 279us/sample - loss: 0.4513 - acc: 0.7813\n",
      "Epoch 71/100\n",
      "4074/4074 [==============================] - 1s 277us/sample - loss: 0.4540 - acc: 0.7808\n",
      "Epoch 72/100\n",
      "4074/4074 [==============================] - 1s 278us/sample - loss: 0.4523 - acc: 0.7850\n",
      "Epoch 73/100\n",
      "4074/4074 [==============================] - 1s 277us/sample - loss: 0.4537 - acc: 0.7828\n",
      "Epoch 74/100\n",
      "4074/4074 [==============================] - 1s 270us/sample - loss: 0.4538 - acc: 0.7811\n",
      "Epoch 75/100\n",
      "4074/4074 [==============================] - 1s 282us/sample - loss: 0.4525 - acc: 0.7823\n",
      "Epoch 76/100\n",
      "4074/4074 [==============================] - 1s 338us/sample - loss: 0.4545 - acc: 0.7842\n",
      "Epoch 77/100\n",
      "4074/4074 [==============================] - 1s 307us/sample - loss: 0.4510 - acc: 0.7791\n",
      "Epoch 78/100\n",
      "4074/4074 [==============================] - 1s 350us/sample - loss: 0.4513 - acc: 0.7830\n",
      "Epoch 79/100\n",
      "4074/4074 [==============================] - 1s 329us/sample - loss: 0.4513 - acc: 0.7855\n",
      "Epoch 80/100\n",
      "4074/4074 [==============================] - 1s 321us/sample - loss: 0.4518 - acc: 0.7835\n",
      "Epoch 81/100\n",
      "4074/4074 [==============================] - 1s 314us/sample - loss: 0.4501 - acc: 0.7813\n",
      "Epoch 82/100\n",
      "4074/4074 [==============================] - 1s 282us/sample - loss: 0.4501 - acc: 0.7798\n",
      "Epoch 83/100\n",
      "4074/4074 [==============================] - 1s 280us/sample - loss: 0.4510 - acc: 0.7825\n",
      "Epoch 84/100\n",
      "4074/4074 [==============================] - 1s 280us/sample - loss: 0.4514 - acc: 0.7847\n",
      "Epoch 85/100\n",
      "4074/4074 [==============================] - 1s 268us/sample - loss: 0.4501 - acc: 0.7830\n",
      "Epoch 86/100\n",
      "4074/4074 [==============================] - 1s 230us/sample - loss: 0.4501 - acc: 0.7820\n",
      "Epoch 87/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4510 - acc: 0.7823\n",
      "Epoch 88/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4512 - acc: 0.7803\n",
      "Epoch 89/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4509 - acc: 0.7801\n",
      "Epoch 90/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4492 - acc: 0.7828\n",
      "Epoch 91/100\n",
      "4074/4074 [==============================] - 1s 230us/sample - loss: 0.4504 - acc: 0.7842\n",
      "Epoch 92/100\n",
      "4074/4074 [==============================] - 1s 255us/sample - loss: 0.4494 - acc: 0.7852\n",
      "Epoch 93/100\n",
      "4074/4074 [==============================] - 1s 291us/sample - loss: 0.4497 - acc: 0.7825\n",
      "Epoch 94/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4472 - acc: 0.7842\n",
      "Epoch 95/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4497 - acc: 0.7845\n",
      "Epoch 96/100\n",
      "4074/4074 [==============================] - 1s 270us/sample - loss: 0.4482 - acc: 0.7852\n",
      "Epoch 97/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4484 - acc: 0.7830\n",
      "Epoch 98/100\n",
      "4074/4074 [==============================] - 1s 242us/sample - loss: 0.4492 - acc: 0.7850\n",
      "Epoch 99/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4480 - acc: 0.7857\n",
      "Epoch 100/100\n",
      "4074/4074 [==============================] - 1s 230us/sample - loss: 0.4483 - acc: 0.7788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14d92efefc8>"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(15, input_shape = (10, ), activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train2, y_train2, epochs=100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 122us/sample - loss: 0.4908 - acc: 0.7540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4907910912036896, 0.754]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_2 = model.predict(X_test)\n",
    "y_predicted_2 = np.asanyarray(y_predicted_2)\n",
    "y_predict_2 = []\n",
    "for i in range(len(y_predicted_2)):\n",
    "    if y_predicted_2[i] > 0.5:\n",
    "        y_predict_2.append(1)\n",
    "    else:\n",
    "        y_predict_2.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.83      1588\n",
      "           1       0.45      0.79      0.57       412\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.69      0.77      0.70      2000\n",
      "weighted avg       0.83      0.75      0.77      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 3rd class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4074, 10), (2000, 10))"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4074/4074 [==============================] - 1s 296us/sample - loss: 0.6674 - acc: 0.5987\n",
      "Epoch 2/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.6284 - acc: 0.6527\n",
      "Epoch 3/100\n",
      "4074/4074 [==============================] - 1s 245us/sample - loss: 0.6005 - acc: 0.6750\n",
      "Epoch 4/100\n",
      "4074/4074 [==============================] - 1s 234us/sample - loss: 0.5758 - acc: 0.7069\n",
      "Epoch 5/100\n",
      "4074/4074 [==============================] - 1s 277us/sample - loss: 0.5548 - acc: 0.7251\n",
      "Epoch 6/100\n",
      "4074/4074 [==============================] - 1s 293us/sample - loss: 0.5419 - acc: 0.7327\n",
      "Epoch 7/100\n",
      "4074/4074 [==============================] - 1s 238us/sample - loss: 0.5303 - acc: 0.7440\n",
      "Epoch 8/100\n",
      "4074/4074 [==============================] - 1s 243us/sample - loss: 0.5260 - acc: 0.7445\n",
      "Epoch 9/100\n",
      "4074/4074 [==============================] - 1s 263us/sample - loss: 0.5191 - acc: 0.7538\n",
      "Epoch 10/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.5097 - acc: 0.7516\n",
      "Epoch 11/100\n",
      "4074/4074 [==============================] - 1s 238us/sample - loss: 0.5052 - acc: 0.7585\n",
      "Epoch 12/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4985 - acc: 0.7587\n",
      "Epoch 13/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4970 - acc: 0.7563\n",
      "Epoch 14/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4926 - acc: 0.7592\n",
      "Epoch 15/100\n",
      "4074/4074 [==============================] - 1s 243us/sample - loss: 0.4902 - acc: 0.7577\n",
      "Epoch 16/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4867 - acc: 0.7661\n",
      "Epoch 17/100\n",
      "4074/4074 [==============================] - 1s 235us/sample - loss: 0.4855 - acc: 0.7624\n",
      "Epoch 18/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4843 - acc: 0.7698\n",
      "Epoch 19/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4832 - acc: 0.7639\n",
      "Epoch 20/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4824 - acc: 0.7644\n",
      "Epoch 21/100\n",
      "4074/4074 [==============================] - 1s 260us/sample - loss: 0.4800 - acc: 0.7680\n",
      "Epoch 22/100\n",
      "4074/4074 [==============================] - 1s 298us/sample - loss: 0.4813 - acc: 0.7658\n",
      "Epoch 23/100\n",
      "4074/4074 [==============================] - 1s 239us/sample - loss: 0.4784 - acc: 0.7720\n",
      "Epoch 24/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4783 - acc: 0.7671\n",
      "Epoch 25/100\n",
      "4074/4074 [==============================] - 1s 272us/sample - loss: 0.4778 - acc: 0.7680\n",
      "Epoch 26/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4779 - acc: 0.7685\n",
      "Epoch 27/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4754 - acc: 0.7683\n",
      "Epoch 28/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4758 - acc: 0.7683\n",
      "Epoch 29/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4762 - acc: 0.7698\n",
      "Epoch 30/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4742 - acc: 0.7671\n",
      "Epoch 31/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4718 - acc: 0.7656\n",
      "Epoch 32/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4709 - acc: 0.7668\n",
      "Epoch 33/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4719 - acc: 0.7690\n",
      "Epoch 34/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4721 - acc: 0.7703\n",
      "Epoch 35/100\n",
      "4074/4074 [==============================] - 1s 235us/sample - loss: 0.4712 - acc: 0.7680\n",
      "Epoch 36/100\n",
      "4074/4074 [==============================] - 1s 234us/sample - loss: 0.4694 - acc: 0.7747\n",
      "Epoch 37/100\n",
      "4074/4074 [==============================] - 1s 275us/sample - loss: 0.4701 - acc: 0.7710\n",
      "Epoch 38/100\n",
      "4074/4074 [==============================] - 1s 298us/sample - loss: 0.4694 - acc: 0.7712\n",
      "Epoch 39/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4669 - acc: 0.7717\n",
      "Epoch 40/100\n",
      "4074/4074 [==============================] - 1s 239us/sample - loss: 0.4685 - acc: 0.7720\n",
      "Epoch 41/100\n",
      "4074/4074 [==============================] - 1s 275us/sample - loss: 0.4683 - acc: 0.7766\n",
      "Epoch 42/100\n",
      "4074/4074 [==============================] - 1s 238us/sample - loss: 0.4669 - acc: 0.7712\n",
      "Epoch 43/100\n",
      "4074/4074 [==============================] - 1s 308us/sample - loss: 0.4668 - acc: 0.7715\n",
      "Epoch 44/100\n",
      "4074/4074 [==============================] - 1s 282us/sample - loss: 0.4641 - acc: 0.7737\n",
      "Epoch 45/100\n",
      "4074/4074 [==============================] - 1s 248us/sample - loss: 0.4651 - acc: 0.7734\n",
      "Epoch 46/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4653 - acc: 0.7742\n",
      "Epoch 47/100\n",
      "4074/4074 [==============================] - 1s 237us/sample - loss: 0.4636 - acc: 0.7744\n",
      "Epoch 48/100\n",
      "4074/4074 [==============================] - 1s 238us/sample - loss: 0.4639 - acc: 0.7725\n",
      "Epoch 49/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4613 - acc: 0.7774\n",
      "Epoch 50/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4645 - acc: 0.7720\n",
      "Epoch 51/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4620 - acc: 0.7749\n",
      "Epoch 52/100\n",
      "4074/4074 [==============================] - 1s 238us/sample - loss: 0.4585 - acc: 0.7791\n",
      "Epoch 53/100\n",
      "4074/4074 [==============================] - 1s 312us/sample - loss: 0.4590 - acc: 0.7815\n",
      "Epoch 54/100\n",
      "4074/4074 [==============================] - 1s 263us/sample - loss: 0.4595 - acc: 0.7788\n",
      "Epoch 55/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4603 - acc: 0.7781\n",
      "Epoch 56/100\n",
      "4074/4074 [==============================] - 1s 237us/sample - loss: 0.4607 - acc: 0.7776\n",
      "Epoch 57/100\n",
      "4074/4074 [==============================] - 1s 249us/sample - loss: 0.4583 - acc: 0.7788\n",
      "Epoch 58/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4582 - acc: 0.7818\n",
      "Epoch 59/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4597 - acc: 0.7798\n",
      "Epoch 60/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4584 - acc: 0.7788\n",
      "Epoch 61/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4553 - acc: 0.7796\n",
      "Epoch 62/100\n",
      "4074/4074 [==============================] - 1s 229us/sample - loss: 0.4577 - acc: 0.7808\n",
      "Epoch 63/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4568 - acc: 0.7757\n",
      "Epoch 64/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4559 - acc: 0.7845\n",
      "Epoch 65/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4582 - acc: 0.7803\n",
      "Epoch 66/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4543 - acc: 0.7852\n",
      "Epoch 67/100\n",
      "4074/4074 [==============================] - 1s 226us/sample - loss: 0.4551 - acc: 0.7761\n",
      "Epoch 68/100\n",
      "4074/4074 [==============================] - 1s 229us/sample - loss: 0.4545 - acc: 0.7838\n",
      "Epoch 69/100\n",
      "4074/4074 [==============================] - 1s 274us/sample - loss: 0.4541 - acc: 0.7865\n",
      "Epoch 70/100\n",
      "4074/4074 [==============================] - 1s 287us/sample - loss: 0.4548 - acc: 0.7806\n",
      "Epoch 71/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4556 - acc: 0.7764\n",
      "Epoch 72/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4517 - acc: 0.7835\n",
      "Epoch 73/100\n",
      "4074/4074 [==============================] - 1s 268us/sample - loss: 0.4524 - acc: 0.7850\n",
      "Epoch 74/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4529 - acc: 0.7847\n",
      "Epoch 75/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4513 - acc: 0.7838\n",
      "Epoch 76/100\n",
      "4074/4074 [==============================] - 1s 238us/sample - loss: 0.4538 - acc: 0.7860\n",
      "Epoch 77/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4504 - acc: 0.7894\n",
      "Epoch 78/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4528 - acc: 0.7796\n",
      "Epoch 79/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4502 - acc: 0.7850\n",
      "Epoch 80/100\n",
      "4074/4074 [==============================] - 1s 233us/sample - loss: 0.4508 - acc: 0.7811\n",
      "Epoch 81/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4511 - acc: 0.7894\n",
      "Epoch 82/100\n",
      "4074/4074 [==============================] - 1s 265us/sample - loss: 0.4512 - acc: 0.7840\n",
      "Epoch 83/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4495 - acc: 0.7872\n",
      "Epoch 84/100\n",
      "4074/4074 [==============================] - 1s 227us/sample - loss: 0.4474 - acc: 0.7889\n",
      "Epoch 85/100\n",
      "4074/4074 [==============================] - 1s 253us/sample - loss: 0.4488 - acc: 0.7828\n",
      "Epoch 86/100\n",
      "4074/4074 [==============================] - 1s 309us/sample - loss: 0.4492 - acc: 0.7823\n",
      "Epoch 87/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4521 - acc: 0.7811\n",
      "Epoch 88/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4488 - acc: 0.7815\n",
      "Epoch 89/100\n",
      "4074/4074 [==============================] - 1s 264us/sample - loss: 0.4486 - acc: 0.7874\n",
      "Epoch 90/100\n",
      "4074/4074 [==============================] - 1s 231us/sample - loss: 0.4519 - acc: 0.7857\n",
      "Epoch 91/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4497 - acc: 0.7877\n",
      "Epoch 92/100\n",
      "4074/4074 [==============================] - 1s 227us/sample - loss: 0.4486 - acc: 0.7887\n",
      "Epoch 93/100\n",
      "4074/4074 [==============================] - 1s 228us/sample - loss: 0.4490 - acc: 0.7877\n",
      "Epoch 94/100\n",
      "4074/4074 [==============================] - ETA: 0s - loss: 0.4515 - acc: 0.784 - 1s 228us/sample - loss: 0.4512 - acc: 0.7828\n",
      "Epoch 95/100\n",
      "4074/4074 [==============================] - 1s 236us/sample - loss: 0.4487 - acc: 0.7865\n",
      "Epoch 96/100\n",
      "4074/4074 [==============================] - 1s 264us/sample - loss: 0.4497 - acc: 0.7791\n",
      "Epoch 97/100\n",
      "4074/4074 [==============================] - 1s 224us/sample - loss: 0.4482 - acc: 0.7855\n",
      "Epoch 98/100\n",
      "4074/4074 [==============================] - 1s 226us/sample - loss: 0.4477 - acc: 0.7887\n",
      "Epoch 99/100\n",
      "4074/4074 [==============================] - 1s 226us/sample - loss: 0.4462 - acc: 0.7855\n",
      "Epoch 100/100\n",
      "4074/4074 [==============================] - 1s 226us/sample - loss: 0.4475 - acc: 0.7835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14d932c2d08>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(15, input_shape = (10, ), activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train3, y_train3, epochs=100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 152us/sample - loss: 0.4235 - acc: 0.7980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4235216660499573, 0.798]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_3 = model.predict(X_test)\n",
    "y_predicted_3 = np.asanyarray(y_predicted_3)\n",
    "y_predict_3 = []\n",
    "for i in range(len(y_predicted_3)):\n",
    "    if y_predicted_3[i] > 0.5:\n",
    "        y_predict_3.append(1)\n",
    "    else:\n",
    "        y_predict_3.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87      1588\n",
      "           1       0.51      0.73      0.60       412\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.71      0.77      0.73      2000\n",
      "weighted avg       0.83      0.80      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 4th class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3889, 10), (2000, 10))"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train4.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3889/3889 [==============================] - 1s 304us/sample - loss: 0.6627 - acc: 0.5971\n",
      "Epoch 2/100\n",
      "3889/3889 [==============================] - 1s 267us/sample - loss: 0.6170 - acc: 0.6583\n",
      "Epoch 3/100\n",
      "3889/3889 [==============================] - 1s 232us/sample - loss: 0.5967 - acc: 0.6791\n",
      "Epoch 4/100\n",
      "3889/3889 [==============================] - 1s 237us/sample - loss: 0.5792 - acc: 0.6974\n",
      "Epoch 5/100\n",
      "3889/3889 [==============================] - 1s 231us/sample - loss: 0.5663 - acc: 0.7118\n",
      "Epoch 6/100\n",
      "3889/3889 [==============================] - 1s 231us/sample - loss: 0.5548 - acc: 0.7143\n",
      "Epoch 7/100\n",
      "3889/3889 [==============================] - 1s 234us/sample - loss: 0.5453 - acc: 0.7295\n",
      "Epoch 8/100\n",
      "3889/3889 [==============================] - 1s 248us/sample - loss: 0.5359 - acc: 0.7331\n",
      "Epoch 9/100\n",
      "3889/3889 [==============================] - 1s 234us/sample - loss: 0.5307 - acc: 0.7398\n",
      "Epoch 10/100\n",
      "3889/3889 [==============================] - 1s 237us/sample - loss: 0.5252 - acc: 0.7403\n",
      "Epoch 11/100\n",
      "3889/3889 [==============================] - 1s 234us/sample - loss: 0.5211 - acc: 0.7460\n",
      "Epoch 12/100\n",
      "3889/3889 [==============================] - 1s 239us/sample - loss: 0.5180 - acc: 0.7400\n",
      "Epoch 13/100\n",
      "3889/3889 [==============================] - 1s 239us/sample - loss: 0.5132 - acc: 0.7449\n",
      "Epoch 14/100\n",
      "3889/3889 [==============================] - 1s 237us/sample - loss: 0.5117 - acc: 0.7429\n",
      "Epoch 15/100\n",
      "3889/3889 [==============================] - 1s 273us/sample - loss: 0.5086 - acc: 0.7490\n",
      "Epoch 16/100\n",
      "3889/3889 [==============================] - 1s 314us/sample - loss: 0.5069 - acc: 0.7447\n",
      "Epoch 17/100\n",
      "3889/3889 [==============================] - 1s 314us/sample - loss: 0.5036 - acc: 0.7524\n",
      "Epoch 18/100\n",
      "3889/3889 [==============================] - 1s 342us/sample - loss: 0.5031 - acc: 0.7521\n",
      "Epoch 19/100\n",
      "3889/3889 [==============================] - 1s 260us/sample - loss: 0.5016 - acc: 0.7478\n",
      "Epoch 20/100\n",
      "3889/3889 [==============================] - 1s 262us/sample - loss: 0.5014 - acc: 0.7547\n",
      "Epoch 21/100\n",
      "3889/3889 [==============================] - 1s 252us/sample - loss: 0.5007 - acc: 0.7552\n",
      "Epoch 22/100\n",
      "3889/3889 [==============================] - 1s 256us/sample - loss: 0.4992 - acc: 0.7483\n",
      "Epoch 23/100\n",
      "3889/3889 [==============================] - 1s 261us/sample - loss: 0.4979 - acc: 0.7495\n",
      "Epoch 24/100\n",
      "3889/3889 [==============================] - 1s 363us/sample - loss: 0.4964 - acc: 0.7501s - loss: 0.4952 - acc: 0.75\n",
      "Epoch 25/100\n",
      "3889/3889 [==============================] - 1s 306us/sample - loss: 0.4966 - acc: 0.7552\n",
      "Epoch 26/100\n",
      "3889/3889 [==============================] - 2s 410us/sample - loss: 0.4939 - acc: 0.7549\n",
      "Epoch 27/100\n",
      "3889/3889 [==============================] - 1s 344us/sample - loss: 0.4921 - acc: 0.7544\n",
      "Epoch 28/100\n",
      "3889/3889 [==============================] - 1s 280us/sample - loss: 0.4916 - acc: 0.7565\n",
      "Epoch 29/100\n",
      "3889/3889 [==============================] - 2s 440us/sample - loss: 0.4901 - acc: 0.7560s - loss: 0.5011 \n",
      "Epoch 30/100\n",
      "3889/3889 [==============================] - 2s 433us/sample - loss: 0.4898 - acc: 0.7562\n",
      "Epoch 31/100\n",
      "3889/3889 [==============================] - 2s 422us/sample - loss: 0.4883 - acc: 0.7585\n",
      "Epoch 32/100\n",
      "3889/3889 [==============================] - 2s 422us/sample - loss: 0.4855 - acc: 0.7555\n",
      "Epoch 33/100\n",
      "3889/3889 [==============================] - 1s 291us/sample - loss: 0.4851 - acc: 0.7603\n",
      "Epoch 34/100\n",
      "3889/3889 [==============================] - 1s 233us/sample - loss: 0.4871 - acc: 0.7611\n",
      "Epoch 35/100\n",
      "3889/3889 [==============================] - 1s 235us/sample - loss: 0.4848 - acc: 0.7555\n",
      "Epoch 36/100\n",
      "3889/3889 [==============================] - 1s 237us/sample - loss: 0.4855 - acc: 0.7575\n",
      "Epoch 37/100\n",
      "3889/3889 [==============================] - 1s 249us/sample - loss: 0.4823 - acc: 0.7611\n",
      "Epoch 38/100\n",
      "3889/3889 [==============================] - 1s 244us/sample - loss: 0.4834 - acc: 0.7578\n",
      "Epoch 39/100\n",
      "3889/3889 [==============================] - 1s 231us/sample - loss: 0.4817 - acc: 0.7585\n",
      "Epoch 40/100\n",
      "3889/3889 [==============================] - 1s 332us/sample - loss: 0.4831 - acc: 0.7555\n",
      "Epoch 41/100\n",
      "3889/3889 [==============================] - 1s 247us/sample - loss: 0.4801 - acc: 0.7614\n",
      "Epoch 42/100\n",
      "3889/3889 [==============================] - 1s 341us/sample - loss: 0.4809 - acc: 0.7585\n",
      "Epoch 43/100\n",
      "3889/3889 [==============================] - 1s 334us/sample - loss: 0.4785 - acc: 0.7591\n",
      "Epoch 44/100\n",
      "3889/3889 [==============================] - 1s 255us/sample - loss: 0.4785 - acc: 0.7616\n",
      "Epoch 45/100\n",
      "3889/3889 [==============================] - 1s 255us/sample - loss: 0.4773 - acc: 0.7642\n",
      "Epoch 46/100\n",
      "3889/3889 [==============================] - 1s 288us/sample - loss: 0.4774 - acc: 0.7619\n",
      "Epoch 47/100\n",
      "3889/3889 [==============================] - 1s 243us/sample - loss: 0.4760 - acc: 0.7619\n",
      "Epoch 48/100\n",
      "3889/3889 [==============================] - 1s 244us/sample - loss: 0.4739 - acc: 0.7611\n",
      "Epoch 49/100\n",
      "3889/3889 [==============================] - 1s 239us/sample - loss: 0.4761 - acc: 0.7655\n",
      "Epoch 50/100\n",
      "3889/3889 [==============================] - 1s 237us/sample - loss: 0.4751 - acc: 0.7650\n",
      "Epoch 51/100\n",
      "3889/3889 [==============================] - 1s 242us/sample - loss: 0.4730 - acc: 0.7678\n",
      "Epoch 52/100\n",
      "3889/3889 [==============================] - 1s 239us/sample - loss: 0.4719 - acc: 0.7691\n",
      "Epoch 53/100\n",
      "3889/3889 [==============================] - 1s 242us/sample - loss: 0.4717 - acc: 0.7647\n",
      "Epoch 54/100\n",
      "3889/3889 [==============================] - 1s 244us/sample - loss: 0.4722 - acc: 0.7616\n",
      "Epoch 55/100\n",
      "3889/3889 [==============================] - 1s 237us/sample - loss: 0.4698 - acc: 0.7663\n",
      "Epoch 56/100\n",
      "3889/3889 [==============================] - 1s 239us/sample - loss: 0.4695 - acc: 0.7696\n",
      "Epoch 57/100\n",
      "3889/3889 [==============================] - 1s 239us/sample - loss: 0.4700 - acc: 0.7639\n",
      "Epoch 58/100\n",
      "3889/3889 [==============================] - 1s 341us/sample - loss: 0.4687 - acc: 0.7706\n",
      "Epoch 59/100\n",
      "3889/3889 [==============================] - 1s 310us/sample - loss: 0.4711 - acc: 0.7704\n",
      "Epoch 60/100\n",
      "3889/3889 [==============================] - 1s 236us/sample - loss: 0.4683 - acc: 0.7709\n",
      "Epoch 61/100\n",
      "3889/3889 [==============================] - 1s 265us/sample - loss: 0.4688 - acc: 0.7704\n",
      "Epoch 62/100\n",
      "3889/3889 [==============================] - 1s 265us/sample - loss: 0.4680 - acc: 0.7688\n",
      "Epoch 63/100\n",
      "3889/3889 [==============================] - 1s 237us/sample - loss: 0.4704 - acc: 0.7645\n",
      "Epoch 64/100\n",
      "3889/3889 [==============================] - 1s 233us/sample - loss: 0.4675 - acc: 0.7729\n",
      "Epoch 65/100\n",
      "3889/3889 [==============================] - 1s 232us/sample - loss: 0.4688 - acc: 0.7675\n",
      "Epoch 66/100\n",
      "3889/3889 [==============================] - 1s 234us/sample - loss: 0.4673 - acc: 0.7719\n",
      "Epoch 67/100\n",
      "3889/3889 [==============================] - 1s 231us/sample - loss: 0.4664 - acc: 0.7724\n",
      "Epoch 68/100\n",
      "3889/3889 [==============================] - 1s 242us/sample - loss: 0.4643 - acc: 0.7742\n",
      "Epoch 69/100\n",
      "3889/3889 [==============================] - 1s 252us/sample - loss: 0.4648 - acc: 0.7727\n",
      "Epoch 70/100\n",
      "3889/3889 [==============================] - 1s 270us/sample - loss: 0.4648 - acc: 0.7745\n",
      "Epoch 71/100\n",
      "3889/3889 [==============================] - 1s 255us/sample - loss: 0.4638 - acc: 0.7735\n",
      "Epoch 72/100\n",
      "3889/3889 [==============================] - 1s 257us/sample - loss: 0.4634 - acc: 0.7714\n",
      "Epoch 73/100\n",
      "3889/3889 [==============================] - 1s 257us/sample - loss: 0.4629 - acc: 0.7706\n",
      "Epoch 74/100\n",
      "3889/3889 [==============================] - 1s 321us/sample - loss: 0.4626 - acc: 0.7747\n",
      "Epoch 75/100\n",
      "3889/3889 [==============================] - 1s 278us/sample - loss: 0.4634 - acc: 0.7768\n",
      "Epoch 76/100\n",
      "3889/3889 [==============================] - 1s 250us/sample - loss: 0.4606 - acc: 0.7763\n",
      "Epoch 77/100\n",
      "3889/3889 [==============================] - 1s 278us/sample - loss: 0.4618 - acc: 0.7755\n",
      "Epoch 78/100\n",
      "3889/3889 [==============================] - 1s 275us/sample - loss: 0.4622 - acc: 0.7704\n",
      "Epoch 79/100\n",
      "3889/3889 [==============================] - 1s 237us/sample - loss: 0.4596 - acc: 0.7742\n",
      "Epoch 80/100\n",
      "3889/3889 [==============================] - 1s 242us/sample - loss: 0.4587 - acc: 0.7763\n",
      "Epoch 81/100\n",
      "3889/3889 [==============================] - 1s 262us/sample - loss: 0.4595 - acc: 0.7786\n",
      "Epoch 82/100\n",
      "3889/3889 [==============================] - 1s 261us/sample - loss: 0.4622 - acc: 0.7729\n",
      "Epoch 83/100\n",
      "3889/3889 [==============================] - 1s 270us/sample - loss: 0.4609 - acc: 0.7724\n",
      "Epoch 84/100\n",
      "3889/3889 [==============================] - 1s 278us/sample - loss: 0.4601 - acc: 0.7727\n",
      "Epoch 85/100\n",
      "3889/3889 [==============================] - 1s 301us/sample - loss: 0.4608 - acc: 0.7750\n",
      "Epoch 86/100\n",
      "3889/3889 [==============================] - 1s 250us/sample - loss: 0.4621 - acc: 0.7693\n",
      "Epoch 87/100\n",
      "3889/3889 [==============================] - 1s 237us/sample - loss: 0.4587 - acc: 0.7750\n",
      "Epoch 88/100\n",
      "3889/3889 [==============================] - 1s 234us/sample - loss: 0.4587 - acc: 0.7763\n",
      "Epoch 89/100\n",
      "3889/3889 [==============================] - 1s 280us/sample - loss: 0.4566 - acc: 0.7763\n",
      "Epoch 90/100\n",
      "3889/3889 [==============================] - 1s 350us/sample - loss: 0.4592 - acc: 0.7750\n",
      "Epoch 91/100\n",
      "3889/3889 [==============================] - 1s 242us/sample - loss: 0.4593 - acc: 0.7765\n",
      "Epoch 92/100\n",
      "3889/3889 [==============================] - 1s 237us/sample - loss: 0.4592 - acc: 0.7704\n",
      "Epoch 93/100\n",
      "3889/3889 [==============================] - 1s 288us/sample - loss: 0.4580 - acc: 0.7763\n",
      "Epoch 94/100\n",
      "3889/3889 [==============================] - 1s 244us/sample - loss: 0.4595 - acc: 0.7781\n",
      "Epoch 95/100\n",
      "3889/3889 [==============================] - 1s 234us/sample - loss: 0.4580 - acc: 0.7717\n",
      "Epoch 96/100\n",
      "3889/3889 [==============================] - 1s 234us/sample - loss: 0.4579 - acc: 0.7789\n",
      "Epoch 97/100\n",
      "3889/3889 [==============================] - 1s 247us/sample - loss: 0.4575 - acc: 0.7791\n",
      "Epoch 98/100\n",
      "3889/3889 [==============================] - 1s 244us/sample - loss: 0.4590 - acc: 0.7763\n",
      "Epoch 99/100\n",
      "3889/3889 [==============================] - 1s 240us/sample - loss: 0.4549 - acc: 0.7781\n",
      "Epoch 100/100\n",
      "3889/3889 [==============================] - 1s 240us/sample - loss: 0.4566 - acc: 0.7783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14d947f8988>"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(15, input_shape = (10, ), activation = 'relu'),\n",
    "    keras.layers.Dense(10, activation = 'relu'),\n",
    "    keras.layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train4, y_train4, epochs=100, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 153us/sample - loss: 0.4385 - acc: 0.7985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4384655442237854, 0.7985]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_4 = model.predict(X_test)\n",
    "y_predicted_4 = np.asanyarray(y_predicted_4)\n",
    "y_predict_4 = []\n",
    "for i in range(len(y_predicted_4)):\n",
    "    if y_predicted_4[i] > 0.5:\n",
    "        y_predict_4.append(1)\n",
    "    else:\n",
    "        y_predict_4.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87      1588\n",
      "           1       0.51      0.72      0.60       412\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.71      0.77      0.73      2000\n",
      "weighted avg       0.83      0.80      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2000, 2000, 2000)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_predict_1),len(y_predict_2), len(y_predict_3),len(y_predict_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority vote out of all the y_predicted values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As i have even classes, so i am taking the copy of maximum precision and recall class(y_predict_3) and when he count \n",
    "is 2 then i am assigning the value as of y_predict_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_result = y_predict_3.copy()\n",
    "for i in range(len(y_predict_4)):\n",
    "    value = y_predict_1[i] + y_predict_2[i]+ y_predict_3[i] + y_predict_4[i]\n",
    "    if value <= 1:\n",
    "        y_predict_result[i] = 0\n",
    "    if value == 2 :\n",
    "        y_predict_result[i] = y_predict_3[i]\n",
    "    if value > 2 :\n",
    "        y_predict_result[i] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final confusion matrix of ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1302,  286],\n",
       "       [ 111,  301]], dtype=int64)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final classification report of ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87      1588\n",
      "           1       0.51      0.73      0.60       412\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.72      0.78      0.74      2000\n",
      "weighted avg       0.84      0.80      0.81      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the f1-score of  the classes 0 - (0.92) and 1 - (0.59) has changed to classes 0 - (0.87) and 1 - (0.60)..  \n",
    "So, overall f1 Score is better than the previous ANN model wihout handling imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
